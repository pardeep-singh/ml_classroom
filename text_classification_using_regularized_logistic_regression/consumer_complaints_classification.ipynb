{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Text Classification using Regularized Logistic Regression<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Overfitting-&amp;-Regualarization-Theory\" data-toc-modified-id=\"Overfitting-&amp;-Regualarization-Theory-1\">Overfitting &amp; Regualarization Theory</a></span><ul class=\"toc-item\"><li><span><a href=\"#Overfitting\" data-toc-modified-id=\"Overfitting-1.1\">Overfitting</a></span></li><li><span><a href=\"#Regularization\" data-toc-modified-id=\"Regularization-1.2\">Regularization</a></span><ul class=\"toc-item\"><li><span><a href=\"#$l_2$-normalisation\" data-toc-modified-id=\"$l_2$-normalisation-1.2.1\">$l_2$ normalisation</a></span></li><li><span><a href=\"#$l_1$-normalisation\" data-toc-modified-id=\"$l_1$-normalisation-1.2.2\">$l_1$ normalisation</a></span></li></ul></li></ul></li><li><span><a href=\"#Machine-Learning-Project-Lifecycle:-Third-Iteration\" data-toc-modified-id=\"Machine-Learning-Project-Lifecycle:-Third-Iteration-2\">Machine Learning Project Lifecycle: Third Iteration</a></span><ul class=\"toc-item\"><li><span><a href=\"#Problem-Statement\" data-toc-modified-id=\"Problem-Statement-2.1\">Problem Statement</a></span></li><li><span><a href=\"#Training-Data\" data-toc-modified-id=\"Training-Data-2.2\">Training Data</a></span></li><li><span><a href=\"#Preprocessing-+-Feature-Engineering\" data-toc-modified-id=\"Preprocessing-+-Feature-Engineering-2.3\">Preprocessing + Feature Engineering</a></span></li><li><span><a href=\"#Machine-Learning-Algorithm:-Regularized-Logistic-Regression\" data-toc-modified-id=\"Machine-Learning-Algorithm:-Regularized-Logistic-Regression-2.4\">Machine Learning Algorithm: Regularized Logistic Regression</a></span><ul class=\"toc-item\"><li><span><a href=\"#Sklearn-Logistic-Regression-with-l2-norm-for-Binary-Classification\" data-toc-modified-id=\"Sklearn-Logistic-Regression-with-l2-norm-for-Binary-Classification-2.4.1\">Sklearn Logistic Regression with l2 norm for Binary Classification</a></span></li><li><span><a href=\"#Logistic-Regression-with-l2-norm-for-Binary-Classification\" data-toc-modified-id=\"Logistic-Regression-with-l2-norm-for-Binary-Classification-2.4.2\">Logistic Regression with l2 norm for Binary Classification</a></span></li></ul></li><li><span><a href=\"#Model-Evaluation\" data-toc-modified-id=\"Model-Evaluation-2.5\">Model Evaluation</a></span></li><li><span><a href=\"#Quality-Metrics\" data-toc-modified-id=\"Quality-Metrics-2.6\">Quality Metrics</a></span></li><li><span><a href=\"#Model-Evaluation-on-Test-Dataset\" data-toc-modified-id=\"Model-Evaluation-on-Test-Dataset-2.7\">Model Evaluation on Test Dataset</a></span></li></ul></li><li><span><a href=\"#Homework\" data-toc-modified-id=\"Homework-3\">Homework</a></span></li><li><span><a href=\"#Resources\" data-toc-modified-id=\"Resources-4\">Resources</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/classification.png\" alt=\"Classification\" style=\"width: 700px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting & Regualarization Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\displaystyle error \\: = \\: \\frac {\\#mistakes \\:} {\\: length \\: of \\: dataset}$\n",
    "\n",
    "$ \\displaystyle accuracy \\: = \\: \\frac {\\#correct \\:} {\\: length \\: of \\: dataset}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is overfitting?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $ training\\_error(w) = 0 $\n",
    "- $ training\\_error(w^*) > training\\_error(\\hat w) $\n",
    "- $ test\\_error(w^*) < test\\_error(\\hat w) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../images/overfitting_plot.jpg' alt='Overfitting' style=\"width: 500px;\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Overfitting as a function of Model complexity**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Description | Plot|\n",
    "|-------------|-----|\n",
    "|Linear Model|<img src='../images/regularization_plots/plot1.png' width=\"300\" height=\"300\">|\n",
    "|Polynomial Model with degree 2|<img src='../images/regularization_plots/plot2.png' width=\"300\" height=\"300\">|\n",
    "|Polynomial Model with degree 3|<img src='../images/regularization_plots/plot3.png' width=\"300\" height=\"300\">|\n",
    "|Polynomial Model with degree 4|<img src='../images/regularization_plots/plot4.png' width=\"300\" height=\"300\">|\n",
    "|Polynomial Model with degree 5|<img src='../images/regularization_plots/plot5.png' width=\"300\" height=\"300\">|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bias Variance Tradeoff**\n",
    "\n",
    "<img src='../images/bias_variance_tradeoff.png' alt='Bias Variance Tradeoff Plot' style=\"width: 600px;\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization\n",
    "\n",
    "- For Linear models, Regularization is all about controlling the magnitude of the coefficients\n",
    "\n",
    "$ total \\: quality = measure \\: of \\: fit - measure \\: of \\: magnitude \\: of \\: coefficients $\n",
    "\n",
    "- $measure \\: of \\: fit = \\ell\\ell(w)$\n",
    "- $\\ell\\ell(w) = {\\displaystyle \\ln \\prod_{i=1}^N P(y_i | x_i, w)}$\n",
    "- $ measure \\: of \\: magnitude \\: of \\: coefficients = \\: ???$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $l_2$ normalisation\n",
    "\n",
    "$ \\| w \\|_2^2 = w_0^2 \\: + \\: w_1^2 \\: + \\: ... \\: + \\: w_d^2$ \n",
    "\n",
    "$ total \\: quality = \\ell\\ell(w) - \\lambda \\| w \\|_2^2 $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How different values of $\\lambda$ impacts the coefficients?**\n",
    "\n",
    "- if $\\lambda = 0$ -> Standard Logistic Regression solution\n",
    "\n",
    "\n",
    "- if $\\lambda = \\infty$ -> All weight is on regularization so $\\hat w = 0$ \n",
    "\n",
    "\n",
    "- if $\\lambda$ is in between -> Balances data fit against the magnitude of coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How it controls Bias Variance tradeoff?**\n",
    "\n",
    "- Large $\\lambda$ -> *high bias, low variance* ie. $\\hat w = 0 for \\lambda = \\infty$\n",
    "\n",
    "\n",
    "- Smalll $\\lambda$ -> *low bias, high variance* ie. higher order polynomial fit with $\\lambda = 0$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision boundry plot for 5 Degree Polynomial model with different Lambda Values**\n",
    "\n",
    "| Description | Plot|\n",
    "|:-------------:|:-----:|\n",
    "|Polynomial Model with degree 5 & Lambda as 1|<img src='../images/regularization_plots/reg_plot1.png' width=\"300\" height=\"300\">|\n",
    "|Polynomial Model with degree 5 & Lambda as .1|<img src='../images/regularization_plots/reg_plot0.1.png' width=\"300\" height=\"300\">|\n",
    "|Polynomial Model with degree 5 & Lambda as .01|<img src='../images/regularization_plots/reg_plot0.01.png' width=\"300\" height=\"300\">|\n",
    "|Polynomial Model with degree 5 & Lambda as .001|<img src='../images/regularization_plots/reg_plot0.001.png' width=\"300\" height=\"300\">|\n",
    "|Polynomial Model with degree 5 & Lambda as .005|<img src='../images/regularization_plots/reg_plot0.005.png' width=\"300\" height=\"300\">|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO: Coefficient Path plot**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**High Level Algorithm**\n",
    "\n",
    "*High Level Algorithm for Single data point*\n",
    "\n",
    "- while not converged:\n",
    "\n",
    "    - $ \\displaystyle w ^ {t + 1} = w ^ {t}  + n {\\displaystyle \\frac{ \\partial l}{\\partial w_j}} - \\lambda \\frac{ \\partial \\| w \\|_2^2}{\\partial w_j}$\n",
    "    \n",
    "$ {\\displaystyle \\frac{ \\partial (w)}{\\partial w_j}} = \\displaystyle \\sum_{i=1}^N h_j(x_i) (1[y_i = +1] - P(y = +1 | x_i, w))$\n",
    "\n",
    "${\\displaystyle \\frac{ \\partial \\| w \\|_2^2}{\\partial w_j}} = {\\displaystyle \\frac{ \\partial [w_0^2 \\: + \\: w_1^2 \\: + ... \\: + \\: w_j^2 \\: + ... \\: + \\: w_d^2]}{\\partial w_j}} = 2 \\lambda w_j$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Example*\n",
    "\n",
    "- $ w_1  = 1$\n",
    "- $n = 0.1$\n",
    "- $\\lambda = 1$\n",
    "\n",
    "| X[1] |  y | $P(y_i)$ | Contribution to $ w_1 $ derivative |\n",
    "|----| ---- | :---------------------: | -------------------------- |\n",
    "| 20    | +1  |         00.75         | ?   |\n",
    "| 10    | -1  |          00.25       | ?   |\n",
    "| 5    | -1  |      00.10        | ?   |\n",
    "\n",
    "**Q) What will be the value of $w_t+1$?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $l_1$ normalisation\n",
    "\n",
    "$ \\| w \\|_1 = | w_0 | \\: + \\: | w_1 | \\: + \\: ... \\: + \\: | w_d |$ \n",
    "\n",
    "$ total \\: quality = \\ell\\ell(w) - \\lambda \\| w \\|_1 $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How different values of $\\lambda$ impacts the coefficients?**\n",
    "\n",
    "- if $\\lambda = 0$ -> Standard Logistic Regression solution\n",
    "\n",
    "\n",
    "- if $\\lambda = \\infty$ -> All weight is on regularization so $\\hat w = 0$ \n",
    "\n",
    "\n",
    "- if $\\lambda$ is in between -> Balances data fit against the magnitude of coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO: Coefficient Path Plot**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Project Lifecycle: Third Iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement\n",
    "\n",
    "Classify the Financial Consumer Complaints into different Product Categories given consumer complaint text.\n",
    "\n",
    "**Product Categories**\n",
    "\n",
    "- Credit reporting, repair, or other\n",
    "- Debt collection\n",
    "- Student loan\n",
    "- Money transfer, virtual currency, or money service\n",
    "- Bank account or service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data\n",
    "\n",
    "[Kaggle: Consumer Complaint Database](https://www.kaggle.com/selener/consumer-complaint-database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "complaints_training_dataset = pd.read_csv('../datasets/consumer_complaints_training_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Complaint_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Credit reporting, repair, or other</td>\n",
       "      <td>My name is  XXXX   XXXX   XXXX , not  XXXX   X...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Credit reporting, repair, or other</td>\n",
       "      <td>I was shocked when I reviewed my credit report...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Credit reporting, repair, or other</td>\n",
       "      <td>Equifax misused of credit file. Disputing acco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Credit reporting, repair, or other</td>\n",
       "      <td>I am disturbed that you continue to list the v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Credit reporting, repair, or other</td>\n",
       "      <td>I went to multiple different credit report web...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Product  \\\n",
       "0  Credit reporting, repair, or other   \n",
       "1  Credit reporting, repair, or other   \n",
       "2  Credit reporting, repair, or other   \n",
       "3  Credit reporting, repair, or other   \n",
       "4  Credit reporting, repair, or other   \n",
       "\n",
       "                                      Complaint_text  \n",
       "0  My name is  XXXX   XXXX   XXXX , not  XXXX   X...  \n",
       "1  I was shocked when I reviewed my credit report...  \n",
       "2  Equifax misused of credit file. Disputing acco...  \n",
       "3  I am disturbed that you continue to list the v...  \n",
       "4  I went to multiple different credit report web...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complaints_training_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000 entries, 0 to 19999\n",
      "Data columns (total 2 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   Product         20000 non-null  object\n",
      " 1   Complaint_text  20000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 312.6+ KB\n"
     ]
    }
   ],
   "source": [
    "complaints_training_dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q) What is the distribution of complaints for each product type?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Credit reporting, repair, or other', 'Debt collection',\n",
       "       'Student loan',\n",
       "       'Money transfer, virtual currency, or money service',\n",
       "       'Bank account or service'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complaints_training_dataset.Product.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Product</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bank account or service</th>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Credit reporting, repair, or other</th>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Debt collection</th>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Money transfer, virtual currency, or money service</th>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Student loan</th>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Count\n",
       "Product                                                  \n",
       "Bank account or service                              4000\n",
       "Credit reporting, repair, or other                   4000\n",
       "Debt collection                                      4000\n",
       "Money transfer, virtual currency, or money service   4000\n",
       "Student loan                                         4000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complaints_training_dataset\\\n",
    "    .groupby('Product')\\\n",
    "    [['Complaint_text']]\\\n",
    "    .count()\\\n",
    "    .rename(columns={'Complaint_text': 'Count'})\\\n",
    "    .sort_values('Count', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q) Find out the Occurances of Duplicate Text messages if any?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19913"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complaints_training_dataset['Complaint_text'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_complaints = complaints_training_dataset['Complaint_text']\\\n",
    "    .value_counts()\\\n",
    "    [complaints_training_dataset['Complaint_text'].value_counts() > 2].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(duplicate_complaints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing + Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "RANDOM_STATE = 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words='english', max_features=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    complaints_training_dataset['Complaint_text'],\n",
    "    complaints_training_dataset['Product'],\n",
    "    test_size=.2,\n",
    "    stratify=complaints_training_dataset['Product'],\n",
    "    random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16000,), (4000,), (16000,), (4000,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_count_vectorizer = count_vectorizer.fit_transform(X_train)\n",
    "X_test_count_vectorizer = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(count_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00', '000', '10', '100', '1000', '10000', '100000', '1005', '11', '110']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer.get_feature_names()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('xxxx', 4976),\n",
       " ('account', 322),\n",
       " ('listed', 2727),\n",
       " ('credit', 1279),\n",
       " ('report', 3828),\n",
       " ('experian', 1842),\n",
       " ('paid', 3234),\n",
       " ('closed', 1021),\n",
       " ('2007', 63),\n",
       " ('like', 2712)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(count_vectorizer.vocabulary_.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16000, 5000), (4000, 5000))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_count_vectorizer.shape, X_test_count_vectorizer.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning Algorithm: Regularized Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sklearn Logistic Regression with l2 norm for Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_binary_classifier = LogisticRegression(penalty='l2',\n",
    "                                               max_iter=101,\n",
    "                                               random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:937: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=101,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=19, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_binary_classifier.fit(X_train_count_vectorizer, y_train == 'Student loan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_binary_classifier_predictions = sklearn_binary_classifier.predict(X_test_count_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9625"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_binary_classifier_score = accuracy_score(y_test == 'Student loan', sklearn_binary_classifier_predictions)\n",
    "sklearn_binary_classifier_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression with l2 norm for Binary Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Estimating Conditional Probability using Link Function**\n",
    "\n",
    "$ \\displaystyle P(y_i = +1 | \\mathbf{x}_i,\\mathbf{w}) = \\frac{1}{1 + \\exp(-\\mathbf{w}^T h(\\mathbf{x}_i))} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(scores):\n",
    "    return 1.0 / (1 + np.exp(-scores))\n",
    "\n",
    "def predict_probability(feature_matrix, coefficients):\n",
    "    scores = np.dot(feature_matrix, coefficients)\n",
    "    predictions = sigmoid(scores)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following outputs must match \n",
      "------------------------------------------------\n",
      "correct_predictions           = [0.98201379 0.26894142]\n",
      "output of predict_probability = [0.98201379 0.26894142]\n"
     ]
    }
   ],
   "source": [
    "dummy_feature_matrix = np.array([[1.,2.,3.], [1.,-1.,-1]])\n",
    "dummy_coefficients = np.array([1., 3., -1.])\n",
    "\n",
    "correct_scores      = np.array( [ 1.*1. + 2.*3. + 3.*(-1.),          1.*1. + (-1.)*3. + (-1.)*(-1.) ] )\n",
    "correct_predictions = np.array( [ 1./(1+np.exp(-correct_scores[0])), 1./(1+np.exp(-correct_scores[1])) ] )\n",
    "\n",
    "print('The following outputs must match ')\n",
    "print('------------------------------------------------')\n",
    "print('correct_predictions           =', correct_predictions)\n",
    "print('output of predict_probability =', predict_probability(dummy_feature_matrix, dummy_coefficients))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute derivative with respect to a single coefficient**\n",
    "\n",
    "- coefficients($w_1 .. w_j$) with **L2 Penalty** will be derived using\n",
    "\n",
    "$\n",
    "\\displaystyle \\frac{\\partial\\ell}{\\partial w_j} = \\sum_{i=1}^N h_j(\\mathbf{x}_i)\\left(\\mathbf{1}[y_i = +1] - P(y_i = +1 | \\mathbf{x}_i, \\mathbf{w})\\right) \\color{red}{-2\\lambda w_j }\n",
    "$\n",
    "\n",
    "- For intercept ($w0$) term\n",
    "\n",
    "$\n",
    "\\displaystyle \\frac{\\partial\\ell}{\\partial w_0} = \\sum_{i=1}^N h_j(\\mathbf{x}_i)\\left(\\mathbf{1}[y_i = +1] - P(y_i = +1 | \\mathbf{x}_i, \\mathbf{w})\\right)\n",
    "$\n",
    "\n",
    "We will now write a function that computes the derivative of log likelihood with respect to a single coefficient $w_j$. The function accepts two arguments:\n",
    "* `errors` vector containing $\\mathbf{1}[y_i = +1] - P(y_i = +1 | \\mathbf{x}_i, \\mathbf{w})$ for all $i$.\n",
    "* `feature` vector containing $h_j(\\mathbf{x}_i)$  for all $i$.\n",
    "* `coefficient` containing the current value of coefficient $w_j$.\n",
    "* `is_intercept` boolean value indicating whether the given coefficient is intercept ($w_0$) or not.\n",
    "* `penalty_type` value represeting the type of regularization($l1 \\: or \\: l2$) to use .\n",
    "* `penalty_value` constant penalty value $\\lambda$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_derivative(errors, feature,\n",
    "                       coefficient=None, is_intercept=None,\n",
    "                       penalty_type=None, penalty_value=None):\n",
    "    derivative = np.dot(errors, feature)\n",
    "    if penalty_type is not None and not is_intercept:\n",
    "        derivative -= 2 * penalty_value * coefficient\n",
    "    return derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute Regularized log likelihood will be given by**\n",
    "\n",
    "$ \\ell\\ell(\\mathbf{w}) = \\sum_{i=1}^N \\Big( (\\mathbf{1}[y_i = +1] - 1)\\mathbf{w}^T h(\\mathbf{x}_i) - \\ln\\left(1 + \\exp(-\\mathbf{w}^T h(\\mathbf{x}_i))\\right) \\Big) \\color{red}{-\\lambda\\|\\mathbf{w}\\|_2^2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_log_likelihood(feature_matrix, target_labels, target_label,\n",
    "                           coefficients, penalty_value=None, penalty_type=0):\n",
    "    indicator = (target_labels == target_label)\n",
    "    scores = np.dot(feature_matrix, coefficients)\n",
    "    if penalty_type == 'l2':\n",
    "        likelihood = np.sum((indicator - 1) * scores - np.log(1 + np.exp(-scores))) \\\n",
    "            - penalty_value * np.sum(coefficients[1:] ** 2)\n",
    "    else:\n",
    "        likelihood = np.sum((indicator - 1) * scores - np.log(1 + np.exp(-scores)))\n",
    "    return likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following outputs must match \n",
      "------------------------------------------------\n",
      "correct_log_likelihood           = -5.331411615436032\n",
      "output of compute_log_likelihood = -5.331411615436032\n"
     ]
    }
   ],
   "source": [
    "dummy_feature_matrix = np.array([[1.,2.,3.], [1.,-1.,-1]])\n",
    "dummy_coefficients = np.array([1., 3., -1.])\n",
    "dummy_sentiment = np.array([-1, 1])\n",
    "\n",
    "correct_indicators = np.array([ -1==+1, 1==+1])\n",
    "correct_scores      = np.array( [ 1.*1. + 2.*3. + 3.*(-1.),  1.*1. + (-1.)*3. + (-1.)*(-1.) ] )\n",
    "correct_first_term  = np.array( [ (correct_indicators[0]-1)*correct_scores[0],\n",
    "                                 (correct_indicators[1]-1)*correct_scores[1] ] )\n",
    "correct_second_term = np.array( [ np.log(1. + np.exp(-correct_scores[0])), \n",
    "                                 np.log(1. + np.exp(-correct_scores[1])) ] )\n",
    "\n",
    "correct_ll          =      sum( [ correct_first_term[0]-correct_second_term[0],\n",
    "                                 correct_first_term[1]-correct_second_term[1] ] ) \n",
    "\n",
    "print('The following outputs must match ')\n",
    "print('------------------------------------------------')\n",
    "print('correct_log_likelihood           =', correct_ll)\n",
    "print('output of compute_log_likelihood =', compute_log_likelihood(dummy_feature_matrix,\n",
    "                                                                   dummy_sentiment,\n",
    "                                                                   1,\n",
    "                                                                   dummy_coefficients))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train Binary Logistic Regression Classifier model using Gradient Ascent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_binary_lr_classifier(\n",
    "        features_matrix, target_labels, target_label,\n",
    "        initial_coefficients, step_size, max_iterations,\n",
    "        penalty_type=None, penalty_value=0, debug=False):\n",
    "    coefficients = np.array(initial_coefficients)\n",
    "    likelihood_values = []\n",
    "    for iteration in range(max_iterations):\n",
    "        predictions = predict_probability(features_matrix, coefficients)\n",
    "        \n",
    "        indicator = (target_labels == target_label)\n",
    "        \n",
    "        errors = indicator - predictions\n",
    "        \n",
    "        for j in range(len(coefficients)):\n",
    "            is_intercept = (j == 0)\n",
    "            derivative = feature_derivative(errors, features_matrix[:, j],\n",
    "                                            coefficients[j], is_intercept,\n",
    "                                            penalty_type, penalty_value)\n",
    "            coefficients[j] += step_size * derivative\n",
    "\n",
    "        lp = compute_log_likelihood(features_matrix, target_labels,\n",
    "                                    target_label, coefficients,\n",
    "                                    penalty_type, penalty_value)\n",
    "        likelihood_values.append(lp)\n",
    "        if debug:\n",
    "            if (iteration <= 100 and iteration % 10 == 0)\\\n",
    "                or (iteration <= 1000 and iteration % 100 == 0)\\\n",
    "                or (iteration <= 10000 and iteration % 1000 == 0)\\\n",
    "                or iteration % 10000 == 0:\n",
    "                print('----------------------------------')\n",
    "                print(f'Iteration: {iteration} -> Likelihood value: {lp} for {target_label} classifier.')\n",
    "                predicted_probabilities = predict_probability(features_matrix, coefficients)\n",
    "                predicted_classes = predicted_probabilities > .5\n",
    "                correct_predictions = predicted_classes == (target_labels == target_label)\n",
    "                print(f'Minimum Probability:{predictions.min()},',\n",
    "                      f'Maximum Probability:{predictions.max()},',\n",
    "                      f'Current Accuracy: {correct_predictions.sum() / len(target_labels)}')\n",
    "    if not debug:\n",
    "        predicted_probabilities = predict_probability(features_matrix, coefficients)\n",
    "        predicted_classes = predicted_probabilities > .5\n",
    "        correct_predictions = predicted_classes == (target_labels == target_label)\n",
    "        print(f'Minimum Probability:{predictions.min()},',\n",
    "              f'Maximum Probability:{predictions.max()},',\n",
    "              f'Current Accuracy: {correct_predictions.sum() / len(target_labels)}')\n",
    "    return coefficients, likelihood_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Utility Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import time\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "LAST_RESULTS_FILE_NAME = None\n",
    "\n",
    "def count_vectorized_features_to_features_matrix(count_vectorized_features):\n",
    "    constant_feature = np.ones((count_vectorized_features.shape[0], 1))\n",
    "    return np.hstack((constant_feature, count_vectorized_features.toarray()))\n",
    "\n",
    "def save_experiment_results(results):\n",
    "    file_name_prefix =  'lr_hyper_params_experiments_results'\n",
    "    file_name = f'{file_name_prefix}_{time.monotonic_ns()}.pkl'\n",
    "    print(file_name)\n",
    "    with open(file_name, 'wb') as results_file:\n",
    "        pickle.dump(results, results_file)\n",
    "    return file_name\n",
    "        \n",
    "def classify(features_matrix, coefficients):\n",
    "    prob_predictions = predict_probability(features_matrix, coefficients)\n",
    "    return prob_predictions > .5\n",
    "\n",
    "def load_hyper_params_results_and_configs(file_path=None):\n",
    "    if file_path and os.path.isfile(file_path):\n",
    "        with open(file_path, 'rb') as file:\n",
    "            return pickle.load(file)\n",
    "    else:\n",
    "        hyper_params_configs = [\n",
    "            {'max_iterations': 101, 'penalty_type': 'l2', 'penalty_value': 0},\n",
    "            {'max_iterations': 501, 'penalty_type': 'l2', 'penalty_value': 0},\n",
    "            {'max_iterations': 1001, 'penalty_type': 'l2', 'penalty_value': 0},\n",
    "            {'max_iterations': 101, 'penalty_type': 'l2', 'penalty_value': 1e1},\n",
    "            {'max_iterations': 501, 'penalty_type': 'l2', 'penalty_value': 1e1},\n",
    "            {'max_iterations': 1001, 'penalty_type': 'l2', 'penalty_value': 1e1},\n",
    "            {'max_iterations': 101, 'penalty_type': 'l2', 'penalty_value': 1e2},\n",
    "            {'max_iterations': 501, 'penalty_type': 'l2', 'penalty_value': 1e2},\n",
    "            {'max_iterations': 1001, 'penalty_type': 'l2', 'penalty_value': 1e2},\n",
    "            {'max_iterations': 101, 'penalty_type': 'l2', 'penalty_value': 1e3},\n",
    "            {'max_iterations': 501, 'penalty_type': 'l2', 'penalty_value': 1e3},\n",
    "            {'max_iterations': 1001, 'penalty_type': 'l2', 'penalty_value': 1e3}]\n",
    "        return sorted(hyper_params_configs, key = lambda config: config['max_iterations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16000, 5001) (5001,) (4000, 5001)\n",
      "---------------------------------\n",
      "{'max_iterations': 101, 'penalty_type': 'l2', 'penalty_value': 0}\n",
      "Minimum Probability:1.7134380244175842e-23, Maximum Probability:1.0, Current Accuracy: 0.9513125\n",
      "---------------------------------\n",
      "{'max_iterations': 101, 'penalty_type': 'l2', 'penalty_value': 10.0}\n",
      "Minimum Probability:2.787848753789075e-23, Maximum Probability:1.0, Current Accuracy: 0.951375\n",
      "---------------------------------\n",
      "{'max_iterations': 101, 'penalty_type': 'l2', 'penalty_value': 100.0}\n",
      "Minimum Probability:1.5642499285839832e-21, Maximum Probability:1.0, Current Accuracy: 0.9500625\n",
      "---------------------------------\n",
      "{'max_iterations': 101, 'penalty_type': 'l2', 'penalty_value': 1000.0}\n",
      "Minimum Probability:2.2096905832488215e-12, Maximum Probability:0.9999999999998876, Current Accuracy: 0.9254375\n",
      "---------------------------------\n",
      "{'max_iterations': 501, 'penalty_type': 'l2', 'penalty_value': 0}\n",
      "Minimum Probability:2.6142295788560316e-28, Maximum Probability:1.0, Current Accuracy: 0.95925\n",
      "---------------------------------\n",
      "{'max_iterations': 501, 'penalty_type': 'l2', 'penalty_value': 10.0}\n",
      "Minimum Probability:3.0545203221791276e-27, Maximum Probability:1.0, Current Accuracy: 0.9584375\n",
      "---------------------------------\n",
      "{'max_iterations': 501, 'penalty_type': 'l2', 'penalty_value': 100.0}\n",
      "Minimum Probability:9.356462064424788e-21, Maximum Probability:1.0, Current Accuracy: 0.9521875\n",
      "---------------------------------\n",
      "{'max_iterations': 501, 'penalty_type': 'l2', 'penalty_value': 1000.0}\n",
      "Minimum Probability:3.760513620310823e-09, Maximum Probability:1.0, Current Accuracy: 0.9084375\n",
      "---------------------------------\n",
      "{'max_iterations': 1001, 'penalty_type': 'l2', 'penalty_value': 0}\n",
      "Minimum Probability:1.0720862287580512e-31, Maximum Probability:1.0, Current Accuracy: 0.9634375\n",
      "---------------------------------\n",
      "{'max_iterations': 1001, 'penalty_type': 'l2', 'penalty_value': 10.0}\n",
      "Minimum Probability:1.2447708711318915e-29, Maximum Probability:1.0, Current Accuracy: 0.9624375\n",
      "---------------------------------\n",
      "{'max_iterations': 1001, 'penalty_type': 'l2', 'penalty_value': 100.0}\n",
      "Minimum Probability:4.66073532162223e-20, Maximum Probability:1.0, Current Accuracy: 0.9525\n",
      "---------------------------------\n",
      "{'max_iterations': 1001, 'penalty_type': 'l2', 'penalty_value': 1000.0}\n",
      "Minimum Probability:5.8330477768213516e-09, Maximum Probability:1.0, Current Accuracy: 0.90775\n",
      "lr_hyper_params_experiments_results_913290388264460.pkl\n"
     ]
    }
   ],
   "source": [
    "# TODO: parallelize this using following\n",
    "# from joblib import Parallel, delayed\n",
    "\n",
    "# def myfun(arg):\n",
    "#      do_stuff\n",
    "#      return result\n",
    "\n",
    "# results = Parallel(n_jobs=-1, verbose=verbosity_level, backend=\"threading\")(\n",
    "#              map(delayed(myfun), arg_instances))\n",
    "\n",
    "import datetime\n",
    "\n",
    "# Hyper Params\n",
    "\n",
    "step_size = 1e-5\n",
    "\n",
    "# Target Variables\n",
    "target_labels, target_label = y_train, 'Student loan'\n",
    "\n",
    "# Feature Matrix & Initial Coefficients\n",
    "X_train_features_matrix = count_vectorized_features_to_features_matrix(X_train_count_vectorizer)\n",
    "X_test_features_matrix = count_vectorized_features_to_features_matrix(X_test_count_vectorizer)\n",
    "\n",
    "initial_coefficients = np.zeros(X_train_features_matrix.shape[1])\n",
    "\n",
    "print(X_train_features_matrix.shape, initial_coefficients.shape, X_test_features_matrix.shape)\n",
    "\n",
    "#hyper_params_experiments_results = load_hyper_params_results_and_configs()\n",
    "hyper_params_experiments_results = load_hyper_params_results_and_configs(\n",
    "    'lr_hyper_params_experiments_results_913290388264460.pkl')\n",
    "\n",
    "\n",
    "for hyper_params in hyper_params_experiments_results:\n",
    "    if 'coeffs' in hyper_params:\n",
    "        continue\n",
    "    print('---------------------------------')\n",
    "    print(hyper_params)\n",
    "    start_time = datetime.datetime.now()\n",
    "    coefficients, likelihood_values = train_binary_lr_classifier(\n",
    "        X_train_features_matrix,\n",
    "        target_labels,\n",
    "        target_label,\n",
    "        initial_coefficients,\n",
    "        step_size = step_size,\n",
    "        max_iterations = hyper_params['max_iterations'],\n",
    "        penalty_type = hyper_params['penalty_type'],\n",
    "        penalty_value = hyper_params['penalty_value']\n",
    "    )\n",
    "    time_delta = datetime.datetime.now() - start_time\n",
    "    hyper_params['coefficients'] = coefficients\n",
    "    hyper_params['likelihood_values'] = likelihood_values\n",
    "    hyper_params['time_delta'] = time_delta\n",
    "    hyper_params['train_dataset_accuracy'] = accuracy_score(\n",
    "        y_train == 'Student loan',\n",
    "        classify(X_train_features_matrix, coefficients))\n",
    "    hyper_params['test_dataset_accuracy'] = accuracy_score(\n",
    "        y_test == 'Student loan',\n",
    "        classify(X_test_features_matrix, coefficients))\n",
    "\n",
    "LAST_RESULTS_FILE_NAME = save_experiment_results(hyper_params_experiments_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter: 101, penalty: l2, lambda: 0, coff sum:-6.470139104175344\n",
      "max_iter: 101, penalty: l2, lambda: 10.0, coff sum:-6.404583738998205\n",
      "max_iter: 101, penalty: l2, lambda: 100.0, coff sum:-5.861191995719484\n",
      "max_iter: 101, penalty: l2, lambda: 1000.0, coff sum:-3.0850758730329035\n",
      "max_iter: 501, penalty: l2, lambda: 0, coff sum:-8.993814468402608\n",
      "max_iter: 501, penalty: l2, lambda: 10.0, coff sum:-8.489069865211473\n",
      "max_iter: 501, penalty: l2, lambda: 100.0, coff sum:-5.35012613669932\n",
      "max_iter: 501, penalty: l2, lambda: 1000.0, coff sum:-0.8443463339801652\n",
      "max_iter: 1001, penalty: l2, lambda: 0, coff sum:-11.837326874631996\n",
      "max_iter: 1001, penalty: l2, lambda: 10.0, coff sum:-10.565074757936022\n",
      "max_iter: 1001, penalty: l2, lambda: 100.0, coff sum:-4.801118054254753\n",
      "max_iter: 1001, penalty: l2, lambda: 1000.0, coff sum:-0.6863518425736136\n"
     ]
    }
   ],
   "source": [
    "max_unregularized_binary_classifier_accuracy = 0\n",
    "max_regularized_binary_classifier_accuracy = 0\n",
    "\n",
    "for hyper_params_result in sorted(\n",
    "    hyper_params_experiments_results,\n",
    "    key=lambda value: [value['max_iterations'], value['penalty_value']],\n",
    "    reverse=False):\n",
    "    if hyper_params_result['penalty_value'] > 0:\n",
    "        max_regularized_binary_classifier_accuracy = max(max_regularized_binary_classifier_accuracy,\n",
    "                                                         hyper_params_result['test_dataset_accuracy'])\n",
    "    else:\n",
    "        max_unregularized_binary_classifier_accuracy = max(max_unregularized_binary_classifier_accuracy,\n",
    "                                                           hyper_params_result['test_dataset_accuracy'])\n",
    "    print(f\"max_iter: {hyper_params_result['max_iterations']},\",\n",
    "          f\"penalty: {hyper_params_result['penalty_type']},\",\n",
    "          f\"lambda: {hyper_params_result['penalty_value']},\",\n",
    "          #f\"train accuracy: {hyper_params_result['train_dataset_accuracy'] * 100},\",\n",
    "          #f\"test accuracy: {hyper_params_result['test_dataset_accuracy'] * 100}\",\n",
    "          #f\"coff len:{len(hyper_params_result['coefficients'])}\",\n",
    "          #f\"likelihood_values len:{len(hyper_params_result['likelihood_values'])}\",\n",
    "          f\"coff sum:{sum(hyper_params_result['coefficients'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn Binary Classifer Accuracy Score: 0.9625\n",
      " LR unregualrized Binary Classifier Accuracy Score: 0.9575\n",
      " LR regualrized Binary Classifier Accuracy Score: 0.95675\n"
     ]
    }
   ],
   "source": [
    "print(f'Sklearn Binary Classifer Accuracy Score: {sklearn_binary_classifier_score}\\n',\n",
    "    f'LR unregualrized Binary Classifier Accuracy Score: {max_unregularized_binary_classifier_accuracy}\\n',\n",
    "    f'LR regualrized Binary Classifier Accuracy Score: {max_regularized_binary_classifier_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation on Test Dataset\n",
    "\n",
    "- Note: Retrain the model using full training [dataset](../datasets/consumer_complaints_training_dataset.csv) & test using the test [dataset](../datasets/consumer_complaints_test_dataset.csv)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework\n",
    "\n",
    "- [Google Form Link](https://forms.gle/qdrRLbikJ3B3NUNv9) Please submit by 23rd April.\n",
    "\n",
    "**Write a microservice which Exposes an endpoint(`/classify`) which takes a single parameter as text & return label, label_probability. Writing this service will require followings things:**\n",
    "\n",
    "- Train a multiclass model using full training dataset (20000 records) & save model coefficients(`custom_one_vs_all_classifiers`) along with vocabulary dict(`count_vectorizer.vocabulary_.items()`) as a json object.\n",
    "- Function which takes a raw text & tokenize the given text. Simple split on punctuations can be used to split the text.\n",
    "- Function which takes a tokenised text & returns a feature matrix using a vocabulary. Row wise length of this matrix should be equal to row wise length of feature matrix used to train the model.\n",
    "- Function which implements `predict_probability` function logic.\n",
    "- Unit tests :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "- [Coordinate Descent & Ascent Methods](https://www.cs.ubc.ca/~jnutini/documents/mlrg_CD.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Text Classification using Regularized Logistic Regression",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
