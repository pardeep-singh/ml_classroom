{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Text Classification using Regularized Logistic Regression<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Regularization-Theory\" data-toc-modified-id=\"Regularization-Theory-1\">Regularization Theory</a></span></li><li><span><a href=\"#Machine-Learning-Project-Lifecycle:-Third-Iteration\" data-toc-modified-id=\"Machine-Learning-Project-Lifecycle:-Third-Iteration-2\">Machine Learning Project Lifecycle: Third Iteration</a></span><ul class=\"toc-item\"><li><span><a href=\"#Problem-Statement\" data-toc-modified-id=\"Problem-Statement-2.1\">Problem Statement</a></span></li><li><span><a href=\"#Training-Data\" data-toc-modified-id=\"Training-Data-2.2\">Training Data</a></span></li><li><span><a href=\"#Preprocessing-+-Feature-Engineering\" data-toc-modified-id=\"Preprocessing-+-Feature-Engineering-2.3\">Preprocessing + Feature Engineering</a></span></li><li><span><a href=\"#Machine-Learning-Algorithm:-Logistic-Regression\" data-toc-modified-id=\"Machine-Learning-Algorithm:-Logistic-Regression-2.4\">Machine Learning Algorithm: Logistic Regression</a></span><ul class=\"toc-item\"><li><span><a href=\"#Using-Sklearn-Implementation-for-Student-Loan-Class-Prediction\" data-toc-modified-id=\"Using-Sklearn-Implementation-for-Student-Loan-Class-Prediction-2.4.1\">Using Sklearn Implementation for Student Loan Class Prediction</a></span></li><li><span><a href=\"#Custom-Implementation-for-Student-Loan-Class-Prediction\" data-toc-modified-id=\"Custom-Implementation-for-Student-Loan-Class-Prediction-2.4.2\">Custom Implementation for Student Loan Class Prediction</a></span></li></ul></li><li><span><a href=\"#Model-Evaluation\" data-toc-modified-id=\"Model-Evaluation-2.5\">Model Evaluation</a></span></li><li><span><a href=\"#Quality-Metrics\" data-toc-modified-id=\"Quality-Metrics-2.6\">Quality Metrics</a></span></li><li><span><a href=\"#Model-Evaluation-on-Test-Dataset\" data-toc-modified-id=\"Model-Evaluation-on-Test-Dataset-2.7\">Model Evaluation on Test Dataset</a></span></li></ul></li><li><span><a href=\"#Homework\" data-toc-modified-id=\"Homework-3\">Homework</a></span></li><li><span><a href=\"#Resources\" data-toc-modified-id=\"Resources-4\">Resources</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/classification.png\" alt=\"Classification\" style=\"width: 700px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Project Lifecycle: Third Iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement\n",
    "\n",
    "Classify the Financial Consumer Complaints into different Product Categories given consumer complaint text.\n",
    "\n",
    "**Product Categories**\n",
    "\n",
    "- Credit reporting, repair, or other\n",
    "- Debt collection\n",
    "- Student loan\n",
    "- Money transfer, virtual currency, or money service\n",
    "- Bank account or service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data\n",
    "\n",
    "[Kaggle: Consumer Complaint Database](https://www.kaggle.com/selener/consumer-complaint-database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "complaints_training_dataset = pd.read_csv('../datasets/consumer_complaints_training_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Complaint_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Credit reporting, repair, or other</td>\n",
       "      <td>My name is  XXXX   XXXX   XXXX , not  XXXX   X...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Credit reporting, repair, or other</td>\n",
       "      <td>I was shocked when I reviewed my credit report...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Credit reporting, repair, or other</td>\n",
       "      <td>Equifax misused of credit file. Disputing acco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Credit reporting, repair, or other</td>\n",
       "      <td>I am disturbed that you continue to list the v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Credit reporting, repair, or other</td>\n",
       "      <td>I went to multiple different credit report web...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Product  \\\n",
       "0  Credit reporting, repair, or other   \n",
       "1  Credit reporting, repair, or other   \n",
       "2  Credit reporting, repair, or other   \n",
       "3  Credit reporting, repair, or other   \n",
       "4  Credit reporting, repair, or other   \n",
       "\n",
       "                                      Complaint_text  \n",
       "0  My name is  XXXX   XXXX   XXXX , not  XXXX   X...  \n",
       "1  I was shocked when I reviewed my credit report...  \n",
       "2  Equifax misused of credit file. Disputing acco...  \n",
       "3  I am disturbed that you continue to list the v...  \n",
       "4  I went to multiple different credit report web...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complaints_training_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000 entries, 0 to 19999\n",
      "Data columns (total 2 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   Product         20000 non-null  object\n",
      " 1   Complaint_text  20000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 312.6+ KB\n"
     ]
    }
   ],
   "source": [
    "complaints_training_dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q) What is the distribution of complaints for each product type?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Credit reporting, repair, or other', 'Debt collection',\n",
       "       'Student loan',\n",
       "       'Money transfer, virtual currency, or money service',\n",
       "       'Bank account or service'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complaints_training_dataset.Product.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Product</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bank account or service</th>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Credit reporting, repair, or other</th>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Debt collection</th>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Money transfer, virtual currency, or money service</th>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Student loan</th>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Count\n",
       "Product                                                  \n",
       "Bank account or service                              4000\n",
       "Credit reporting, repair, or other                   4000\n",
       "Debt collection                                      4000\n",
       "Money transfer, virtual currency, or money service   4000\n",
       "Student loan                                         4000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complaints_training_dataset\\\n",
    "    .groupby('Product')\\\n",
    "    [['Complaint_text']]\\\n",
    "    .count()\\\n",
    "    .rename(columns={'Complaint_text': 'Count'})\\\n",
    "    .sort_values('Count', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q) Find out the Occurances of Duplicate Text messages if any?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19913"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complaints_training_dataset['Complaint_text'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_complaints = complaints_training_dataset['Complaint_text']\\\n",
    "    .value_counts()\\\n",
    "    [complaints_training_dataset['Complaint_text'].value_counts() > 2].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(duplicate_complaints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing + Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "RANDOM_STATE = 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words='english', max_features=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    complaints_training_dataset['Complaint_text'],\n",
    "    complaints_training_dataset['Product'],\n",
    "    test_size=.2,\n",
    "    stratify=complaints_training_dataset['Product'],\n",
    "    random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16000,), (4000,), (16000,), (4000,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_count_vectorizer = count_vectorizer.fit_transform(X_train)\n",
    "X_test_count_vectorizer = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(count_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00', '000', '10', '100', '1000', '10000', '100000', '1005', '11', '110']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer.get_feature_names()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('xxxx', 4976),\n",
       " ('account', 322),\n",
       " ('listed', 2727),\n",
       " ('credit', 1279),\n",
       " ('report', 3828),\n",
       " ('experian', 1842),\n",
       " ('paid', 3234),\n",
       " ('closed', 1021),\n",
       " ('2007', 63),\n",
       " ('like', 2712)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(count_vectorizer.vocabulary_.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16000, 5000), (4000, 5000))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_count_vectorizer.shape, X_test_count_vectorizer.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning Algorithm: Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Sklearn Implementation for Student Loan Class Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_binary_classifier = LogisticRegression(penalty='none',\n",
    "                                               max_iter=101,\n",
    "                                               random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:937: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=101,\n",
       "                   multi_class='auto', n_jobs=None, penalty='none',\n",
       "                   random_state=19, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_binary_classifier.fit(X_train_count_vectorizer, y_train == 'Student loan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_binary_classifier_predictions = sklearn_binary_classifier.predict(X_test_count_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.954"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_binary_classifier_score = accuracy_score(y_test == 'Student loan', sklearn_binary_classifier_predictions)\n",
    "sklearn_binary_classifier_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom Implementation for Student Loan Class Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Estimating Conditional Probability using Link Function**\n",
    "\n",
    "$ \\displaystyle P(y_i = +1 | \\mathbf{x}_i,\\mathbf{w}) = \\frac{1}{1 + \\exp(-\\mathbf{w}^T h(\\mathbf{x}_i))} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(scores):\n",
    "    return 1.0 / (1 + np.exp(-scores))\n",
    "\n",
    "def predict_probability(feature_matrix, coefficients):\n",
    "    scores = np.dot(feature_matrix, coefficients)\n",
    "    predictions = sigmoid(scores)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following outputs must match \n",
      "------------------------------------------------\n",
      "correct_predictions           = [0.98201379 0.26894142]\n",
      "output of predict_probability = [0.98201379 0.26894142]\n"
     ]
    }
   ],
   "source": [
    "dummy_feature_matrix = np.array([[1.,2.,3.], [1.,-1.,-1]])\n",
    "dummy_coefficients = np.array([1., 3., -1.])\n",
    "\n",
    "correct_scores      = np.array( [ 1.*1. + 2.*3. + 3.*(-1.),          1.*1. + (-1.)*3. + (-1.)*(-1.) ] )\n",
    "correct_predictions = np.array( [ 1./(1+np.exp(-correct_scores[0])), 1./(1+np.exp(-correct_scores[1])) ] )\n",
    "\n",
    "print('The following outputs must match ')\n",
    "print('------------------------------------------------')\n",
    "print('correct_predictions           =', correct_predictions)\n",
    "print('output of predict_probability =', predict_probability(dummy_feature_matrix, dummy_coefficients))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute derivative with respect to a single coefficient**\n",
    "\n",
    "$\n",
    "\\displaystyle \\frac{\\partial\\ell}{\\partial w_j} = \\sum_{i=1}^N h_j(\\mathbf{x}_i)\\left(\\mathbf{1}[y_i = +1] - P(y_i = +1 | \\mathbf{x}_i, \\mathbf{w})\\right)\n",
    "$\n",
    "\n",
    "We will now write a function that computes the derivative of log likelihood with respect to a single coefficient $w_j$. The function accepts two arguments:\n",
    "* `errors` vector containing $\\mathbf{1}[y_i = +1] - P(y_i = +1 | \\mathbf{x}_i, \\mathbf{w})$ for all $i$.\n",
    "* `feature` vector containing $h_j(\\mathbf{x}_i)$  for all $i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_derivative(errors, feature):\n",
    "    derivative = np.dot(errors, feature)\n",
    "    return derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute log likelihood which is given by**\n",
    "\n",
    "$ \\ell\\ell(\\mathbf{w}) = \\sum_{i=1}^N \\Big( (\\mathbf{1}[y_i = +1] - 1)\\mathbf{w}^T h(\\mathbf{x}_i) - \\ln\\left(1 + \\exp(-\\mathbf{w}^T h(\\mathbf{x}_i))\\right) \\Big) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_log_likelihood(feature_matrix, target_labels, target_label, coefficients):\n",
    "    indicator = (target_labels == target_label)\n",
    "    scores = np.dot(feature_matrix, coefficients)\n",
    "    likelihood = np.sum((indicator - 1) * scores - np.log(1 + np.exp(-scores)))\n",
    "    return likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following outputs must match \n",
      "------------------------------------------------\n",
      "correct_log_likelihood           = -5.331411615436032\n",
      "output of compute_log_likelihood = -5.331411615436032\n"
     ]
    }
   ],
   "source": [
    "dummy_feature_matrix = np.array([[1.,2.,3.], [1.,-1.,-1]])\n",
    "dummy_coefficients = np.array([1., 3., -1.])\n",
    "dummy_sentiment = np.array([-1, 1])\n",
    "\n",
    "correct_indicators = np.array([ -1==+1, 1==+1])\n",
    "correct_scores      = np.array( [ 1.*1. + 2.*3. + 3.*(-1.),  1.*1. + (-1.)*3. + (-1.)*(-1.) ] )\n",
    "correct_first_term  = np.array( [ (correct_indicators[0]-1)*correct_scores[0],\n",
    "                                 (correct_indicators[1]-1)*correct_scores[1] ] )\n",
    "correct_second_term = np.array( [ np.log(1. + np.exp(-correct_scores[0])), \n",
    "                                 np.log(1. + np.exp(-correct_scores[1])) ] )\n",
    "\n",
    "correct_ll          =      sum( [ correct_first_term[0]-correct_second_term[0],\n",
    "                                 correct_first_term[1]-correct_second_term[1] ] ) \n",
    "\n",
    "print('The following outputs must match ')\n",
    "print('------------------------------------------------')\n",
    "print('correct_log_likelihood           =', correct_ll)\n",
    "print('output of compute_log_likelihood =', compute_log_likelihood(dummy_feature_matrix,\n",
    "                                                                   dummy_sentiment,\n",
    "                                                                   1,\n",
    "                                                                   dummy_coefficients))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Any Questions????**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train Binary Logistic Regression Classifier model using Gradient Ascent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_binary_lr_classifier(\n",
    "        features_matrix, target_labels, target_label,\n",
    "        initial_coefficients, step_size, max_iterations):\n",
    "    coefficients = np.array(initial_coefficients)\n",
    "    for iteration in range(max_iterations):\n",
    "        predictions = predict_probability(features_matrix, coefficients)\n",
    "        \n",
    "        indicator = (target_labels == target_label)\n",
    "        \n",
    "        errors = indicator - predictions\n",
    "        \n",
    "        for j in range(len(coefficients)):\n",
    "            derivative = feature_derivative(errors, features_matrix[:, j])\n",
    "            coefficients[j] += step_size * derivative\n",
    "            \n",
    "        if (iteration <= 100 and iteration % 10 == 0)\\\n",
    "            or (iteration <= 1000 and iteration % 100 == 0)\\\n",
    "            or (iteration <= 10000 and iteration % 1000 == 0)\\\n",
    "            or iteration % 10000 == 0:\n",
    "            lp = compute_log_likelihood(features_matrix, target_labels,\n",
    "                                        target_label, coefficients)\n",
    "            print('----------------------------------')\n",
    "            print(f'Iteration: {iteration} -> Likelihood value: {lp} for {target_label} classifier.')\n",
    "            predicted_probabilities = predict_probability(features_matrix, coefficients)\n",
    "            predicted_classes = predicted_probabilities > .5\n",
    "            correct_predictions = predicted_classes == (target_labels == target_label)\n",
    "            print(f'Minimum Probability:{predictions.min()},',\n",
    "                  f'Maximum Probability:{predictions.max()},',\n",
    "                  f'Current Accuracy: {correct_predictions.sum() / len(target_labels)}')\n",
    "    return coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_vectorized_features_to_features_matrix(count_vectorized_features):\n",
    "    constant_feature = np.ones((count_vectorized_features.shape[0], 1))\n",
    "    return np.hstack((constant_feature, count_vectorized_features.toarray()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16000, 5001) (5001,)\n",
      "----------------------------------\n",
      "Iteration: 0 -> Likelihood value: -18351.684887894677 for Student loan classifier.\n",
      "Minimum Probability:0.5, Maximum Probability:0.5, Current Accuracy: 0.8033125\n",
      "----------------------------------\n",
      "Iteration: 10 -> Likelihood value: -6158.331576286401 for Student loan classifier.\n",
      "Minimum Probability:2.7025490668168023e-09, Maximum Probability:0.999999999982643, Current Accuracy: 0.891375\n",
      "----------------------------------\n",
      "Iteration: 20 -> Likelihood value: -4004.3037195526767 for Student loan classifier.\n",
      "Minimum Probability:7.215761438369419e-14, Maximum Probability:0.9999999999956504, Current Accuracy: 0.9375625\n",
      "----------------------------------\n",
      "Iteration: 30 -> Likelihood value: -3576.3360214762492 for Student loan classifier.\n",
      "Minimum Probability:5.858595032778935e-17, Maximum Probability:0.9999999999208924, Current Accuracy: 0.9464375\n",
      "----------------------------------\n",
      "Iteration: 40 -> Likelihood value: -3346.3896591181638 for Student loan classifier.\n",
      "Minimum Probability:8.833001575542133e-19, Maximum Probability:0.9999999999980189, Current Accuracy: 0.947375\n",
      "----------------------------------\n",
      "Iteration: 50 -> Likelihood value: -3181.0500433098778 for Student loan classifier.\n",
      "Minimum Probability:4.3447869881649386e-20, Maximum Probability:0.9999999999999394, Current Accuracy: 0.9485625\n",
      "----------------------------------\n",
      "Iteration: 60 -> Likelihood value: -3053.8486684609256 for Student loan classifier.\n",
      "Minimum Probability:4.303610847556147e-21, Maximum Probability:0.9999999999999969, Current Accuracy: 0.9495625\n",
      "----------------------------------\n",
      "Iteration: 70 -> Likelihood value: -2951.5747855770987 for Student loan classifier.\n",
      "Minimum Probability:6.897466389644764e-22, Maximum Probability:0.9999999999999998, Current Accuracy: 0.9503125\n",
      "----------------------------------\n",
      "Iteration: 80 -> Likelihood value: -2866.706736556511 for Student loan classifier.\n",
      "Minimum Probability:1.5712146744469538e-22, Maximum Probability:1.0, Current Accuracy: 0.950625\n",
      "----------------------------------\n",
      "Iteration: 90 -> Likelihood value: -2794.598994320963 for Student loan classifier.\n",
      "Minimum Probability:4.6754263216271544e-23, Maximum Probability:1.0, Current Accuracy: 0.951125\n",
      "----------------------------------\n",
      "Iteration: 100 -> Likelihood value: -2732.205581932696 for Student loan classifier.\n",
      "Minimum Probability:1.7134380244175842e-23, Maximum Probability:1.0, Current Accuracy: 0.9513125\n"
     ]
    }
   ],
   "source": [
    "# Hyper Paramters\n",
    "step_size, max_iterations =1e-5, 101\n",
    "\n",
    "# Target Variables\n",
    "target_labels, target_label = y_train, 'Student loan'\n",
    "\n",
    "# Feature Matrix & Initial Coefficients\n",
    "X_train_features_matrix = count_vectorized_features_to_features_matrix(X_train_count_vectorizer)\n",
    "initial_coefficients = np.zeros(X_train_features_matrix.shape[1])\n",
    "\n",
    "print(X_train_features_matrix.shape, initial_coefficients.shape)\n",
    "\n",
    "custom_binary_classifier_coeffs = train_binary_lr_classifier(\n",
    "    X_train_features_matrix,\n",
    "    target_labels,\n",
    "    target_label,\n",
    "    initial_coefficients,\n",
    "    step_size,\n",
    "    max_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.947"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_features_matrix = count_vectorized_features_to_features_matrix(X_test_count_vectorizer)\n",
    "custom_binary_classifier_predictions = predict_probability(X_test_features_matrix,\n",
    "                                                           custom_binary_classifier_coeffs) > .5\n",
    "custom_binary_classifier_score = accuracy_score(y_test == 'Student loan',\n",
    "                                                custom_binary_classifier_predictions)\n",
    "custom_binary_classifier_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.954, 0.947)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_binary_classifier_score, custom_binary_classifier_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:937: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:937: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:937: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:937: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:937: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "cv_scores = cross_val_score(LogisticRegression(penalty='none', max_iter=101, random_state=RANDOM_STATE),\n",
    "                            X_train_count_vectorizer,\n",
    "                            y_train,\n",
    "                            cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8332499999999999\n",
      "[0.82875   0.8365625 0.825625  0.841875  0.8334375]\n"
     ]
    }
   ],
   "source": [
    "print(cv_scores.mean())\n",
    "print(cv_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (accuracy_score,\n",
    "                             confusion_matrix)\n",
    "\n",
    "import seaborn as sns;\n",
    "sns.set()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation on Test Dataset\n",
    "\n",
    "- Note: Retrain the model using full training [dataset](../datasets/consumer_complaints_training_dataset.csv) & test using the test [dataset](../datasets/consumer_complaints_test_dataset.csv)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Text Classification using Regularized Logistic Regression",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
