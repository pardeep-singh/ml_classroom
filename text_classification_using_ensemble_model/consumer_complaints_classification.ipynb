{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Text Classification using Ensemble Model<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Ensemble-Learning\" data-toc-modified-id=\"Ensemble-Learning-1\">Ensemble Learning</a></span><ul class=\"toc-item\"><li><span><a href=\"#What-is-Ensemble-Learning?\" data-toc-modified-id=\"What-is-Ensemble-Learning?-1.1\">What is Ensemble Learning?</a></span></li><li><span><a href=\"#Bagging\" data-toc-modified-id=\"Bagging-1.2\">Bagging</a></span></li><li><span><a href=\"#Boosting\" data-toc-modified-id=\"Boosting-1.3\">Boosting</a></span></li><li><span><a href=\"#Stacking\" data-toc-modified-id=\"Stacking-1.4\">Stacking</a></span></li></ul></li><li><span><a href=\"#Machine-Learning-Project-Lifecycle:-Fourth-Iteration\" data-toc-modified-id=\"Machine-Learning-Project-Lifecycle:-Fourth-Iteration-2\">Machine Learning Project Lifecycle: Fourth Iteration</a></span><ul class=\"toc-item\"><li><span><a href=\"#Problem-Statement\" data-toc-modified-id=\"Problem-Statement-2.1\">Problem Statement</a></span></li><li><span><a href=\"#Training-Data\" data-toc-modified-id=\"Training-Data-2.2\">Training Data</a></span></li><li><span><a href=\"#Preprocessing-+-Feature-Engineering\" data-toc-modified-id=\"Preprocessing-+-Feature-Engineering-2.3\">Preprocessing + Feature Engineering</a></span></li><li><span><a href=\"#Machine-Learning-Algorithm:-Ensemble-Learning\" data-toc-modified-id=\"Machine-Learning-Algorithm:-Ensemble-Learning-2.4\">Machine Learning Algorithm: Ensemble Learning</a></span><ul class=\"toc-item\"><li><span><a href=\"#Naive-Bayes\" data-toc-modified-id=\"Naive-Bayes-2.4.1\">Naive Bayes</a></span></li><li><span><a href=\"#Logistic-Regression\" data-toc-modified-id=\"Logistic-Regression-2.4.2\">Logistic Regression</a></span></li><li><span><a href=\"#Ensemble-Model-1:-Bagging-using-Naive-Bayes\" data-toc-modified-id=\"Ensemble-Model-1:-Bagging-using-Naive-Bayes-2.4.3\">Ensemble Model 1: Bagging using Naive Bayes</a></span></li><li><span><a href=\"#Ensemble-Model-2:-Bagging-using-LR\" data-toc-modified-id=\"Ensemble-Model-2:-Bagging-using-LR-2.4.4\">Ensemble Model 2: Bagging using LR</a></span></li><li><span><a href=\"#Ensemble-Model-3:-Boosting-using-Naive-Bayes\" data-toc-modified-id=\"Ensemble-Model-3:-Boosting-using-Naive-Bayes-2.4.5\">Ensemble Model 3: Boosting using Naive Bayes</a></span></li><li><span><a href=\"#Ensemble-Model-4:-Boosting-Using-LR\" data-toc-modified-id=\"Ensemble-Model-4:-Boosting-Using-LR-2.4.6\">Ensemble Model 4: Boosting Using LR</a></span></li><li><span><a href=\"#Ensemble-Model-5:-Basic-Stacking-using-Naive-Bayes-&amp;-LR\" data-toc-modified-id=\"Ensemble-Model-5:-Basic-Stacking-using-Naive-Bayes-&amp;-LR-2.4.7\">Ensemble Model 5: Basic Stacking using Naive Bayes &amp; LR</a></span></li><li><span><a href=\"#Ensemble-Model-6:-Stacking-using-Naive-Bayes-&amp;-LR\" data-toc-modified-id=\"Ensemble-Model-6:-Stacking-using-Naive-Bayes-&amp;-LR-2.4.8\">Ensemble Model 6: Stacking using Naive Bayes &amp; LR</a></span></li></ul></li><li><span><a href=\"#Model-Evaluation\" data-toc-modified-id=\"Model-Evaluation-2.5\">Model Evaluation</a></span></li><li><span><a href=\"#Quality-Metrics\" data-toc-modified-id=\"Quality-Metrics-2.6\">Quality Metrics</a></span></li><li><span><a href=\"#Model-Evaluation-on-Test-Dataset\" data-toc-modified-id=\"Model-Evaluation-on-Test-Dataset-2.7\">Model Evaluation on Test Dataset</a></span></li></ul></li><li><span><a href=\"#Homework\" data-toc-modified-id=\"Homework-3\">Homework</a></span></li><li><span><a href=\"#Resources\" data-toc-modified-id=\"Resources-4\">Resources</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/classification.png\" alt=\"Classification\" style=\"width: 700px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Ensemble Learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<img src='../images/bagging_example.png' alt='Overfitting' style=\"width: 500px;\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../images/stacking_example.png' alt='Overfitting' style=\"width: 700px;\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Project Lifecycle: Fourth Iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Problem Statement\n",
    "\n",
    "Classify the Financial Consumer Complaints into different Product Categories given consumer complaint text.\n",
    "\n",
    "**Product Categories**\n",
    "\n",
    "- Credit reporting, repair, or other\n",
    "- Debt collection\n",
    "- Student loan\n",
    "- Money transfer, virtual currency, or money service\n",
    "- Bank account or service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Training Data\n",
    "\n",
    "[Kaggle: Consumer Complaint Database](https://www.kaggle.com/selener/consumer-complaint-database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "complaints_training_dataset = pd.read_csv('../datasets/consumer_complaints_training_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Complaint_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Credit reporting, repair, or other</td>\n",
       "      <td>My name is  XXXX   XXXX   XXXX , not  XXXX   X...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Credit reporting, repair, or other</td>\n",
       "      <td>I was shocked when I reviewed my credit report...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Credit reporting, repair, or other</td>\n",
       "      <td>Equifax misused of credit file. Disputing acco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Credit reporting, repair, or other</td>\n",
       "      <td>I am disturbed that you continue to list the v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Credit reporting, repair, or other</td>\n",
       "      <td>I went to multiple different credit report web...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Product  \\\n",
       "0  Credit reporting, repair, or other   \n",
       "1  Credit reporting, repair, or other   \n",
       "2  Credit reporting, repair, or other   \n",
       "3  Credit reporting, repair, or other   \n",
       "4  Credit reporting, repair, or other   \n",
       "\n",
       "                                      Complaint_text  \n",
       "0  My name is  XXXX   XXXX   XXXX , not  XXXX   X...  \n",
       "1  I was shocked when I reviewed my credit report...  \n",
       "2  Equifax misused of credit file. Disputing acco...  \n",
       "3  I am disturbed that you continue to list the v...  \n",
       "4  I went to multiple different credit report web...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complaints_training_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000 entries, 0 to 19999\n",
      "Data columns (total 2 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   Product         20000 non-null  object\n",
      " 1   Complaint_text  20000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 312.6+ KB\n"
     ]
    }
   ],
   "source": [
    "complaints_training_dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Q) What is the distribution of complaints for each product type?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Credit reporting, repair, or other', 'Debt collection',\n",
       "       'Student loan',\n",
       "       'Money transfer, virtual currency, or money service',\n",
       "       'Bank account or service'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complaints_training_dataset.Product.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Product</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bank account or service</th>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Credit reporting, repair, or other</th>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Debt collection</th>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Money transfer, virtual currency, or money service</th>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Student loan</th>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Count\n",
       "Product                                                  \n",
       "Bank account or service                              4000\n",
       "Credit reporting, repair, or other                   4000\n",
       "Debt collection                                      4000\n",
       "Money transfer, virtual currency, or money service   4000\n",
       "Student loan                                         4000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complaints_training_dataset\\\n",
    "    .groupby('Product')\\\n",
    "    [['Complaint_text']]\\\n",
    "    .count()\\\n",
    "    .rename(columns={'Complaint_text': 'Count'})\\\n",
    "    .sort_values('Count', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Q) Find out the Occurances of Duplicate Text messages if any?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19913"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complaints_training_dataset['Complaint_text'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "duplicate_complaints = complaints_training_dataset['Complaint_text']\\\n",
    "    .value_counts()\\\n",
    "    [complaints_training_dataset['Complaint_text'].value_counts() > 2].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(duplicate_complaints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Preprocessing + Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "RANDOM_STATE = 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words='english', max_features=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    complaints_training_dataset['Complaint_text'],\n",
    "    complaints_training_dataset['Product'],\n",
    "    test_size=.2,\n",
    "    stratify=complaints_training_dataset['Product'],\n",
    "    random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16000,), (4000,), (16000,), (4000,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train_count_vectorizer = count_vectorizer.fit_transform(X_train)\n",
    "X_test_count_vectorizer = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(count_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00', '000', '10', '100', '1000', '10000', '100000', '1005', '11', '110']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer.get_feature_names()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('xxxx', 4976),\n",
       " ('account', 322),\n",
       " ('listed', 2727),\n",
       " ('credit', 1279),\n",
       " ('report', 3828),\n",
       " ('experian', 1842),\n",
       " ('paid', 3234),\n",
       " ('closed', 1021),\n",
       " ('2007', 63),\n",
       " ('like', 2712)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(count_vectorizer.vocabulary_.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16000, 5000), (4000, 5000))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_count_vectorizer.shape, X_test_count_vectorizer.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning Algorithm: Ensemble Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.859"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "naive_bayes = MultinomialNB()\n",
    "\n",
    "naive_bayes.fit(X_train_count_vectorizer, y_train)\n",
    "\n",
    "naive_bayes_predictions = naive_bayes.predict(X_test_count_vectorizer)\n",
    "\n",
    "naive_bayes_accuracy_score = accuracy_score(y_test, naive_bayes_predictions)\n",
    "\n",
    "naive_bayes_accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:937: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.84075"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(penalty='l2', max_iter=501, random_state=RANDOM_STATE)\n",
    "\n",
    "lr.fit(X_train_count_vectorizer, y_train)\n",
    "\n",
    "lr_predictions = lr.predict(X_test_count_vectorizer)\n",
    "\n",
    "lr_accuracy_score = accuracy_score(y_test, lr_predictions)\n",
    "lr_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85.9 84.075\n"
     ]
    }
   ],
   "source": [
    "print(naive_bayes_accuracy_score * 100, lr_accuracy_score * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86.75"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, ensembled_predictions) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensemble Model 1: Bagging using Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16000, 24253)\n",
      "Model 0 training set accuracy: 0.7374375\n",
      "Model 1 training set accuracy: 0.73825\n",
      "Model 2 training set accuracy: 0.7318125\n",
      "Model 3 training set accuracy: 0.7554375\n",
      "Model 4 training set accuracy: 0.72125\n",
      "Mean Accuracy of individual models is 0.7368374999999999\n",
      "Bagging Model Accuracy is 0.78175\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "count_vectorizer_with_all_features = CountVectorizer(stop_words='english')\n",
    "\n",
    "X_train_count_vect_with_all_features = count_vectorizer_with_all_features.fit_transform(\n",
    "    X_train)\n",
    "X_test_count_vect_with_all_features = count_vectorizer_with_all_features.transform(\n",
    "    X_test)\n",
    "\n",
    "print(X_train_count_vect_with_all_features.shape)\n",
    "\n",
    "bagging_naive_bayes_models = []\n",
    "model_counts = 5\n",
    "features_size = 5000\n",
    "bagging_nb_training_set_accuracies = []\n",
    "\n",
    "for index in range(model_counts):\n",
    "    features_index = np.random.choice(X_train_count_vect_with_all_features.shape[0],\n",
    "                                     features_size,\n",
    "                                     replace=True)\n",
    "    features = X_train_count_vect_with_all_features[:, features_index]\n",
    "    nb_model = MultinomialNB()\n",
    "    nb_model.fit(features, y_train)\n",
    "    training_set_accuracy = accuracy_score(y_train, nb_model.predict(features))\n",
    "    print(f'Model {index} training set accuracy: {training_set_accuracy}')\n",
    "    bagging_nb_training_set_accuracies.append(training_set_accuracy)\n",
    "    bagging_naive_bayes_models.append([nb_model, features_index])\n",
    "    \n",
    "bagging_nb_predictions = []\n",
    "for test_row in X_test_count_vect_with_all_features:\n",
    "    local_predictions = []\n",
    "    for index in range(model_counts):\n",
    "        test_features = test_row[0, bagging_naive_bayes_models[index][1]]\n",
    "        local_predictions.append(bagging_naive_bayes_models[index][0].predict(test_features)[0])\n",
    "    bagging_nb_predictions.append(Counter(local_predictions).most_common()[0][0])\n",
    "\n",
    "bagging_nb_test_set_accuracy = accuracy_score(y_test, bagging_nb_predictions)\n",
    "bagging_nb_mean_training_set_accuracy = sum(bagging_nb_training_set_accuracies) / len(bagging_nb_training_set_accuracies)\n",
    "print(f'Mean Accuracy of individual models is {bagging_nb_mean_training_set_accuracy}')\n",
    "print(f'Bagging Model Accuracy is {bagging_nb_test_set_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensemble Model 2: Bagging using LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0 training set accuracy: 0.806\n",
      "Model 1 training set accuracy: 0.8079375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:937: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2 training set accuracy: 0.7999375\n",
      "Model 3 training set accuracy: 0.806\n",
      "Model 4 training set accuracy: 0.8215\n",
      "Mean Accuracy of individual models is 0.8082750000000001\n",
      "Bagging Model Accuracy is 0.78075\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "count_vectorizer_with_all_features = CountVectorizer(stop_words='english')\n",
    "\n",
    "X_train_count_vect_with_all_features = count_vectorizer_with_all_features.fit_transform(\n",
    "    X_train)\n",
    "X_test_count_vect_with_all_features = count_vectorizer_with_all_features.transform(\n",
    "    X_test)\n",
    "\n",
    "bagging_lr_models = []\n",
    "model_counts = 5\n",
    "features_size = 5000\n",
    "bagging_lr_training_set_accuracies = []\n",
    "bagging_lr_predictions = []\n",
    "\n",
    "for index in range(model_counts):\n",
    "    features_index = np.random.choice(X_train_count_vect_with_all_features.shape[0],\n",
    "                                     features_size,\n",
    "                                     replace=True)\n",
    "    features = X_train_count_vect_with_all_features[:, features_index]\n",
    "    lr_model = LogisticRegression(penalty='l2', max_iter=501, random_state=RANDOM_STATE)\n",
    "    lr_model.fit(features, y_train)\n",
    "    training_set_accuracy = accuracy_score(y_train, lr_model.predict(features))\n",
    "    print(f'Model {index} training set accuracy: {training_set_accuracy}')\n",
    "    bagging_lr_training_set_accuracies.append(training_set_accuracy)\n",
    "    bagging_lr_models.append([lr_model, features_index])\n",
    "    \n",
    "for test_row in X_test_count_vect_with_all_features:\n",
    "    local_predictions = []\n",
    "    for index in range(model_counts):\n",
    "        test_features = test_row[0, bagging_lr_models[index][1]]\n",
    "        local_predictions.append(bagging_lr_models[index][0].predict(test_features)[0])\n",
    "    bagging_lr_predictions.append(Counter(local_predictions).most_common()[0][0])\n",
    "\n",
    "print(f'Mean Accuracy of individual models is {sum(bagging_lr_training_set_accuracies) / len(bagging_lr_training_set_accuracies)}')\n",
    "print(f'Bagging Model Accuracy is {accuracy_score(y_test, bagging_lr_predictions)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 5000) (5000,)\n",
      "Model 0 training set accuracy: 0.998\n",
      "(5000, 5000) (5000,)\n",
      "Model 1 training set accuracy: 0.9976\n",
      "(5000, 5000) (5000,)\n",
      "Model 2 training set accuracy: 0.9992\n",
      "(5000, 5000) (5000,)\n",
      "Model 3 training set accuracy: 0.9982\n",
      "(5000, 5000) (5000,)\n",
      "Model 4 training set accuracy: 0.997\n",
      "Mean Accuracy of individual models is 0.998\n",
      "Bagging Model Accuracy is 0.8495\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "bagging_lr_models2 = []\n",
    "model_counts = 5\n",
    "max_rows = 5000\n",
    "bagging_lr_training_set_accuracies2 = []\n",
    "bagging_lr_predictions2 = []\n",
    "\n",
    "for index in range(model_counts):\n",
    "    rows_index = np.random.choice(X_train.shape[0],\n",
    "                                  max_rows,\n",
    "                                  replace=True)\n",
    "    mini_count_vect = CountVectorizer(stop_words='english', max_features=5000)\n",
    "    mini_X_train = mini_count_vect.fit_transform(X_train.iloc[rows_index])\n",
    "    mini_y_train = y_train.iloc[rows_index]\n",
    "    print(mini_X_train.shape, mini_y_train.shape)\n",
    "    \n",
    "    lr_model = LogisticRegression(penalty='l2', max_iter=501, random_state=RANDOM_STATE)\n",
    "    lr_model.fit(mini_X_train, mini_y_train)\n",
    "    training_set_accuracy = accuracy_score(mini_y_train, lr_model.predict(mini_X_train))\n",
    "    print(f'Model {index} training set accuracy: {training_set_accuracy}')\n",
    "    bagging_lr_training_set_accuracies2.append(training_set_accuracy)\n",
    "    bagging_lr_models2.append([lr_model, mini_count_vect])\n",
    "    \n",
    "for test_row in X_test:\n",
    "    local_predictions = []\n",
    "    for index in range(model_counts):\n",
    "        test_features = bagging_lr_models2[index][1].transform([test_row])\n",
    "        local_predictions.append(bagging_lr_models2[index][0].predict(test_features)[0])\n",
    "    bagging_lr_predictions2.append(Counter(local_predictions).most_common()[0][0])\n",
    "\n",
    "print(f'Mean Accuracy of individual models is {sum(bagging_lr_training_set_accuracies2) / len(bagging_lr_training_set_accuracies2)}')\n",
    "print(f'Bagging Model Accuracy is {accuracy_score(y_test, bagging_lr_predictions2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensemble Model 3: Boosting using Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.396"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaboost = AdaBoostClassifier(MultinomialNB(), n_estimators=500,\n",
    "                              random_state=RANDOM_STATE)\n",
    "\n",
    "adaboost.fit(X_train_count_vectorizer, y_train)\n",
    "\n",
    "predictions = adaboost.predict(X_test_count_vectorizer)\n",
    "\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensemble Model 4: Boosting Using LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80975"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaboost = AdaBoostClassifier(LogisticRegression(max_iter=500), n_estimators=10,\n",
    "                              random_state=RANDOM_STATE)\n",
    "\n",
    "adaboost.fit(X_train_count_vectorizer, y_train)\n",
    "\n",
    "predictions = adaboost.predict(X_test_count_vectorizer)\n",
    "\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensemble Model 5: Basic Stacking using Naive Bayes & LR\n",
    "\n",
    "- Make prediction using Naive Bayes & LR.\n",
    "- Final output will be *max(NB prediction, LR prediction)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembled_predictions = []\n",
    "same_predictions, same_and_correct_predictions,\\\n",
    "    mismatch_naive_bayes_prediction, mismatch_lr_prediction= 0, 0, 0, 0\n",
    "for i, input_row in enumerate(X_test_count_vectorizer):\n",
    "    naive_bayes_prediction = naive_bayes.predict(input_row)\n",
    "    lr_prediction = lr.predict(input_row)\n",
    "    naive_bayes_max_prob = naive_bayes.predict_proba(input_row).max()\n",
    "    lr_max_prob = lr.predict_proba(input_row).max()\n",
    "    if naive_bayes_prediction == lr_prediction:\n",
    "        ensembled_predictions.append(naive_bayes_prediction)\n",
    "        same_predictions += 1\n",
    "        if naive_bayes_prediction == y_test_list[i]:\n",
    "            same_and_correct_predictions += 1\n",
    "    elif naive_bayes_max_prob > lr_max_prob:\n",
    "        ensembled_predictions.append(naive_bayes_prediction)\n",
    "        mismatch_naive_bayes_prediction += 1\n",
    "    elif lr_max_prob > naive_bayes_max_prob:\n",
    "        ensembled_predictions.append(lr_prediction)\n",
    "        mismatch_lr_prediction += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensemble Model 6: Stacking using Naive Bayes & LR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Quality Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import (accuracy_score,\n",
    "                             confusion_matrix)\n",
    "\n",
    "import seaborn as sns;\n",
    "sns.set()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Model Evaluation on Test Dataset\n",
    "\n",
    "- Note: Retrain the model using full training [dataset](../datasets/consumer_complaints_training_dataset.csv) & test using the test [dataset](../datasets/consumer_complaints_test_dataset.csv)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Resources\n",
    "\n",
    "- [Model Ensembles](https://www.youtube.com/watch?v=ZeAv5k71AS4)\n",
    "- [Bagging](https://www.youtube.com/watch?v=1zSkR2xFWKg&t=9s)\n",
    "- [Boosting](https://www.youtube.com/watch?v=ZqbPS7TvhqM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Text Classification using Ensemble Model",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
