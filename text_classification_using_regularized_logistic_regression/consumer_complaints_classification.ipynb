{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Text Classification using Regularized Logistic Regression<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Regularization-Theory\" data-toc-modified-id=\"Regularization-Theory-1\">Regularization Theory</a></span></li><li><span><a href=\"#Machine-Learning-Project-Lifecycle:-Third-Iteration\" data-toc-modified-id=\"Machine-Learning-Project-Lifecycle:-Third-Iteration-2\">Machine Learning Project Lifecycle: Third Iteration</a></span><ul class=\"toc-item\"><li><span><a href=\"#Problem-Statement\" data-toc-modified-id=\"Problem-Statement-2.1\">Problem Statement</a></span></li><li><span><a href=\"#Training-Data\" data-toc-modified-id=\"Training-Data-2.2\">Training Data</a></span></li><li><span><a href=\"#Preprocessing-+-Feature-Engineering\" data-toc-modified-id=\"Preprocessing-+-Feature-Engineering-2.3\">Preprocessing + Feature Engineering</a></span></li><li><span><a href=\"#Machine-Learning-Algorithm:-Logistic-Regression\" data-toc-modified-id=\"Machine-Learning-Algorithm:-Logistic-Regression-2.4\">Machine Learning Algorithm: Logistic Regression</a></span><ul class=\"toc-item\"><li><span><a href=\"#Using-Sklearn-Implementation-for-Student-Loan-Class-Prediction\" data-toc-modified-id=\"Using-Sklearn-Implementation-for-Student-Loan-Class-Prediction-2.4.1\">Using Sklearn Implementation for Student Loan Class Prediction</a></span></li><li><span><a href=\"#Custom-Implementation-for-Student-Loan-Class-Prediction-using-l2-penalty\" data-toc-modified-id=\"Custom-Implementation-for-Student-Loan-Class-Prediction-using-l2-penalty-2.4.2\">Custom Implementation for Student Loan Class Prediction using l2 penalty</a></span></li><li><span><a href=\"#util-fns\" data-toc-modified-id=\"util-fns-2.4.3\">util fns</a></span></li><li><span><a href=\"#Evaluate-different-hyper-parameters-on-test-dataset\" data-toc-modified-id=\"Evaluate-different-hyper-parameters-on-test-dataset-2.4.4\">Evaluate different hyper parameters on test dataset</a></span></li></ul></li><li><span><a href=\"#Model-Evaluation\" data-toc-modified-id=\"Model-Evaluation-2.5\">Model Evaluation</a></span></li><li><span><a href=\"#Quality-Metrics\" data-toc-modified-id=\"Quality-Metrics-2.6\">Quality Metrics</a></span></li><li><span><a href=\"#Model-Evaluation-on-Test-Dataset\" data-toc-modified-id=\"Model-Evaluation-on-Test-Dataset-2.7\">Model Evaluation on Test Dataset</a></span></li></ul></li><li><span><a href=\"#Homework\" data-toc-modified-id=\"Homework-3\">Homework</a></span></li><li><span><a href=\"#Resources\" data-toc-modified-id=\"Resources-4\">Resources</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/classification.png\" alt=\"Classification\" style=\"width: 700px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Project Lifecycle: Third Iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement\n",
    "\n",
    "Classify the Financial Consumer Complaints into different Product Categories given consumer complaint text.\n",
    "\n",
    "**Product Categories**\n",
    "\n",
    "- Credit reporting, repair, or other\n",
    "- Debt collection\n",
    "- Student loan\n",
    "- Money transfer, virtual currency, or money service\n",
    "- Bank account or service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data\n",
    "\n",
    "[Kaggle: Consumer Complaint Database](https://www.kaggle.com/selener/consumer-complaint-database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "complaints_training_dataset = pd.read_csv('../datasets/consumer_complaints_training_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Complaint_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Credit reporting, repair, or other</td>\n",
       "      <td>My name is  XXXX   XXXX   XXXX , not  XXXX   X...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Credit reporting, repair, or other</td>\n",
       "      <td>I was shocked when I reviewed my credit report...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Credit reporting, repair, or other</td>\n",
       "      <td>Equifax misused of credit file. Disputing acco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Credit reporting, repair, or other</td>\n",
       "      <td>I am disturbed that you continue to list the v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Credit reporting, repair, or other</td>\n",
       "      <td>I went to multiple different credit report web...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Product  \\\n",
       "0  Credit reporting, repair, or other   \n",
       "1  Credit reporting, repair, or other   \n",
       "2  Credit reporting, repair, or other   \n",
       "3  Credit reporting, repair, or other   \n",
       "4  Credit reporting, repair, or other   \n",
       "\n",
       "                                      Complaint_text  \n",
       "0  My name is  XXXX   XXXX   XXXX , not  XXXX   X...  \n",
       "1  I was shocked when I reviewed my credit report...  \n",
       "2  Equifax misused of credit file. Disputing acco...  \n",
       "3  I am disturbed that you continue to list the v...  \n",
       "4  I went to multiple different credit report web...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complaints_training_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000 entries, 0 to 19999\n",
      "Data columns (total 2 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   Product         20000 non-null  object\n",
      " 1   Complaint_text  20000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 312.6+ KB\n"
     ]
    }
   ],
   "source": [
    "complaints_training_dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q) What is the distribution of complaints for each product type?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Credit reporting, repair, or other', 'Debt collection',\n",
       "       'Student loan',\n",
       "       'Money transfer, virtual currency, or money service',\n",
       "       'Bank account or service'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complaints_training_dataset.Product.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Product</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bank account or service</th>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Credit reporting, repair, or other</th>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Debt collection</th>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Money transfer, virtual currency, or money service</th>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Student loan</th>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Count\n",
       "Product                                                  \n",
       "Bank account or service                              4000\n",
       "Credit reporting, repair, or other                   4000\n",
       "Debt collection                                      4000\n",
       "Money transfer, virtual currency, or money service   4000\n",
       "Student loan                                         4000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complaints_training_dataset\\\n",
    "    .groupby('Product')\\\n",
    "    [['Complaint_text']]\\\n",
    "    .count()\\\n",
    "    .rename(columns={'Complaint_text': 'Count'})\\\n",
    "    .sort_values('Count', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q) Find out the Occurances of Duplicate Text messages if any?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19913"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complaints_training_dataset['Complaint_text'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_complaints = complaints_training_dataset['Complaint_text']\\\n",
    "    .value_counts()\\\n",
    "    [complaints_training_dataset['Complaint_text'].value_counts() > 2].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(duplicate_complaints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing + Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "RANDOM_STATE = 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words='english', max_features=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    complaints_training_dataset['Complaint_text'],\n",
    "    complaints_training_dataset['Product'],\n",
    "    test_size=.2,\n",
    "    stratify=complaints_training_dataset['Product'],\n",
    "    random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16000,), (4000,), (16000,), (4000,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_count_vectorizer = count_vectorizer.fit_transform(X_train)\n",
    "X_test_count_vectorizer = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(count_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00', '000', '10', '100', '1000', '10000', '100000', '1005', '11', '110']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer.get_feature_names()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('xxxx', 4976),\n",
       " ('account', 322),\n",
       " ('listed', 2727),\n",
       " ('credit', 1279),\n",
       " ('report', 3828),\n",
       " ('experian', 1842),\n",
       " ('paid', 3234),\n",
       " ('closed', 1021),\n",
       " ('2007', 63),\n",
       " ('like', 2712)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(count_vectorizer.vocabulary_.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16000, 5000), (4000, 5000))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_count_vectorizer.shape, X_test_count_vectorizer.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning Algorithm: Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Sklearn Implementation for Student Loan Class Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_binary_classifier = LogisticRegression(penalty='none',\n",
    "                                               max_iter=101,\n",
    "                                               random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:937: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=101,\n",
       "                   multi_class='auto', n_jobs=None, penalty='none',\n",
       "                   random_state=19, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_binary_classifier.fit(X_train_count_vectorizer, y_train == 'Student loan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_binary_classifier_predictions = sklearn_binary_classifier.predict(X_test_count_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.954"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_binary_classifier_score = accuracy_score(y_test == 'Student loan', sklearn_binary_classifier_predictions)\n",
    "sklearn_binary_classifier_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom Implementation for Student Loan Class Prediction using l2 penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Estimating Conditional Probability using Link Function**\n",
    "\n",
    "$ \\displaystyle P(y_i = +1 | \\mathbf{x}_i,\\mathbf{w}) = \\frac{1}{1 + \\exp(-\\mathbf{w}^T h(\\mathbf{x}_i))} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(scores):\n",
    "    return 1.0 / (1 + np.exp(-scores))\n",
    "\n",
    "def predict_probability(feature_matrix, coefficients):\n",
    "    scores = np.dot(feature_matrix, coefficients)\n",
    "    predictions = sigmoid(scores)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following outputs must match \n",
      "------------------------------------------------\n",
      "correct_predictions           = [0.98201379 0.26894142]\n",
      "output of predict_probability = [0.98201379 0.26894142]\n"
     ]
    }
   ],
   "source": [
    "dummy_feature_matrix = np.array([[1.,2.,3.], [1.,-1.,-1]])\n",
    "dummy_coefficients = np.array([1., 3., -1.])\n",
    "\n",
    "correct_scores      = np.array( [ 1.*1. + 2.*3. + 3.*(-1.),          1.*1. + (-1.)*3. + (-1.)*(-1.) ] )\n",
    "correct_predictions = np.array( [ 1./(1+np.exp(-correct_scores[0])), 1./(1+np.exp(-correct_scores[1])) ] )\n",
    "\n",
    "print('The following outputs must match ')\n",
    "print('------------------------------------------------')\n",
    "print('correct_predictions           =', correct_predictions)\n",
    "print('output of predict_probability =', predict_probability(dummy_feature_matrix, dummy_coefficients))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute derivative with respect to a single coefficient**\n",
    "\n",
    "- coefficients($w_1 .. w_j$) with **L1 Penalty** will be derived using\n",
    "\n",
    "$\n",
    "\\displaystyle \\frac{\\partial\\ell}{\\partial w_j} = \\sum_{i=1}^N h_j(\\mathbf{x}_i)\\left(\\mathbf{1}[y_i = +1] - P(y_i = +1 | \\mathbf{x}_i, \\mathbf{w})\\right) \\color{red}{-\\lambda w_j }\n",
    "$\n",
    "\n",
    "- coefficients($w_1 .. w_j$) with **L2 Penalty** will be derived using\n",
    "\n",
    "$\n",
    "\\displaystyle \\frac{\\partial\\ell}{\\partial w_j} = \\sum_{i=1}^N h_j(\\mathbf{x}_i)\\left(\\mathbf{1}[y_i = +1] - P(y_i = +1 | \\mathbf{x}_i, \\mathbf{w})\\right) \\color{red}{-2\\lambda w_j }\n",
    "$\n",
    "\n",
    "- For intercept ($w0$) term\n",
    "\n",
    "$\n",
    "\\displaystyle \\frac{\\partial\\ell}{\\partial w_0} = \\sum_{i=1}^N h_j(\\mathbf{x}_i)\\left(\\mathbf{1}[y_i = +1] - P(y_i = +1 | \\mathbf{x}_i, \\mathbf{w})\\right)\n",
    "$\n",
    "\n",
    "We will now write a function that computes the derivative of log likelihood with respect to a single coefficient $w_j$. The function accepts two arguments:\n",
    "* `errors` vector containing $\\mathbf{1}[y_i = +1] - P(y_i = +1 | \\mathbf{x}_i, \\mathbf{w})$ for all $i$.\n",
    "* `feature` vector containing $h_j(\\mathbf{x}_i)$  for all $i$.\n",
    "* `coefficient` containing the current value of coefficient $w_j$.\n",
    "* `is_intercept` boolean value indicating whether the given coefficient is intercept ($w_0$) or not.\n",
    "* `penalty_type` value represeting the type of regularization($l1 \\: or \\: l2$) to use .\n",
    "* `penalty_value` constant penalty value $\\lambda$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_derivative(errors, feature, coefficient=None, is_intercept=None,\n",
    "                       penalty_type=None, penalty_value=None):\n",
    "    derivative = np.dot(errors, feature)\n",
    "    if penalty_type is not None and not is_intercept:\n",
    "        if penalty_type == 'l2':\n",
    "            # TODO: Check if 2 * penalty_value * coefficient is correct or penalty_value * (coefficient ** 2)\n",
    "            derivative -= 2 * penalty_value * coefficient\n",
    "        elif penalty_type == 'l1':\n",
    "            derivative -= penalty_value * coefficient\n",
    "    return derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute Regularized log likelihood will be given by**\n",
    "\n",
    "- For $l1$ norm regularization\n",
    "\n",
    "$ \\ell\\ell(\\mathbf{w}) = \\sum_{i=1}^N \\Big( (\\mathbf{1}[y_i = +1] - 1)\\mathbf{w}^T h(\\mathbf{x}_i) - \\ln\\left(1 + \\exp(-\\mathbf{w}^T h(\\mathbf{x}_i))\\right) \\Big) \\color{red}{-\\lambda\\|\\mathbf{w}\\|}$\n",
    "\n",
    "- For $l2$ regularization\n",
    "\n",
    "$ \\ell\\ell(\\mathbf{w}) = \\sum_{i=1}^N \\Big( (\\mathbf{1}[y_i = +1] - 1)\\mathbf{w}^T h(\\mathbf{x}_i) - \\ln\\left(1 + \\exp(-\\mathbf{w}^T h(\\mathbf{x}_i))\\right) \\Big) \\color{red}{-\\lambda\\|\\mathbf{w}\\|_2^2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_log_likelihood(feature_matrix, target_labels, target_label,\n",
    "                           coefficients, penalty_value=None, penalty_type=0):\n",
    "    indicator = (target_labels == target_label)\n",
    "    scores = np.dot(feature_matrix, coefficients)\n",
    "    if penalty_type == 'l2':\n",
    "        likelihood = np.sum((indicator - 1) * scores - np.log(1 + np.exp(-scores))) \\\n",
    "            - penalty_value * np.sum(coefficients[1:] ** 2)\n",
    "    elif penalty_type == 'l1':\n",
    "        likelihood = np.sum((indicator - 1) * scores - np.log(1 + np.exp(-scores))) \\\n",
    "            - penalty_value * np.sum(coefficients[1:])\n",
    "    else:\n",
    "        likelihood = np.sum((indicator - 1) * scores - np.log(1 + np.exp(-scores)))\n",
    "    return likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following outputs must match \n",
      "------------------------------------------------\n",
      "correct_log_likelihood           = -5.331411615436032\n",
      "output of compute_log_likelihood = -5.331411615436032\n"
     ]
    }
   ],
   "source": [
    "dummy_feature_matrix = np.array([[1.,2.,3.], [1.,-1.,-1]])\n",
    "dummy_coefficients = np.array([1., 3., -1.])\n",
    "dummy_sentiment = np.array([-1, 1])\n",
    "\n",
    "correct_indicators = np.array([ -1==+1, 1==+1])\n",
    "correct_scores      = np.array( [ 1.*1. + 2.*3. + 3.*(-1.),  1.*1. + (-1.)*3. + (-1.)*(-1.) ] )\n",
    "correct_first_term  = np.array( [ (correct_indicators[0]-1)*correct_scores[0],\n",
    "                                 (correct_indicators[1]-1)*correct_scores[1] ] )\n",
    "correct_second_term = np.array( [ np.log(1. + np.exp(-correct_scores[0])), \n",
    "                                 np.log(1. + np.exp(-correct_scores[1])) ] )\n",
    "\n",
    "correct_ll          =      sum( [ correct_first_term[0]-correct_second_term[0],\n",
    "                                 correct_first_term[1]-correct_second_term[1] ] ) \n",
    "\n",
    "print('The following outputs must match ')\n",
    "print('------------------------------------------------')\n",
    "print('correct_log_likelihood           =', correct_ll)\n",
    "print('output of compute_log_likelihood =', compute_log_likelihood(dummy_feature_matrix,\n",
    "                                                                   dummy_sentiment,\n",
    "                                                                   1,\n",
    "                                                                   dummy_coefficients))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Any Questions????**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train Binary Logistic Regression Classifier model using Gradient Ascent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_binary_lr_classifier(\n",
    "        features_matrix, target_labels, target_label,\n",
    "        initial_coefficients, step_size, max_iterations,\n",
    "        penalty_type=None, penalty_value=0, debug=False):\n",
    "    coefficients = np.array(initial_coefficients)\n",
    "    likelihood_values = []\n",
    "    for iteration in range(max_iterations):\n",
    "        predictions = predict_probability(features_matrix, coefficients)\n",
    "        \n",
    "        indicator = (target_labels == target_label)\n",
    "        \n",
    "        errors = indicator - predictions\n",
    "        \n",
    "        for j in range(len(coefficients)):\n",
    "            is_intercept = (j == 0)\n",
    "            derivative = feature_derivative(errors, features_matrix[:, j],\n",
    "                                            coefficients[j], is_intercept,\n",
    "                                            penalty_type, penalty_value)\n",
    "            coefficients[j] += step_size * derivative\n",
    "\n",
    "        lp = compute_log_likelihood(features_matrix, target_labels,\n",
    "                                    target_label, coefficients,\n",
    "                                    penalty_type, penalty_value)\n",
    "        likelihood_values.append(lp)\n",
    "        if debug:\n",
    "            if (iteration <= 100 and iteration % 10 == 0)\\\n",
    "                or (iteration <= 1000 and iteration % 100 == 0)\\\n",
    "                or (iteration <= 10000 and iteration % 1000 == 0)\\\n",
    "                or iteration % 10000 == 0:\n",
    "                print('----------------------------------')\n",
    "                print(f'Iteration: {iteration} -> Likelihood value: {lp} for {target_label} classifier.')\n",
    "                predicted_probabilities = predict_probability(features_matrix, coefficients)\n",
    "                predicted_classes = predicted_probabilities > .5\n",
    "                correct_predictions = predicted_classes == (target_labels == target_label)\n",
    "                print(f'Minimum Probability:{predictions.min()},',\n",
    "                      f'Maximum Probability:{predictions.max()},',\n",
    "                      f'Current Accuracy: {correct_predictions.sum() / len(target_labels)}')\n",
    "    if not debug:\n",
    "        predicted_probabilities = predict_probability(features_matrix, coefficients)\n",
    "        predicted_classes = predicted_probabilities > .5\n",
    "        correct_predictions = predicted_classes == (target_labels == target_label)\n",
    "        print(f'Minimum Probability:{predictions.min()},',\n",
    "              f'Maximum Probability:{predictions.max()},',\n",
    "              f'Current Accuracy: {correct_predictions.sum() / len(target_labels)}')\n",
    "    return coefficients, likelihood_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### util fns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import time\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "LAST_RESULTS_FILE_NAME = None\n",
    "\n",
    "def count_vectorized_features_to_features_matrix(count_vectorized_features):\n",
    "    constant_feature = np.ones((count_vectorized_features.shape[0], 1))\n",
    "    return np.hstack((constant_feature, count_vectorized_features.toarray()))\n",
    "\n",
    "def save_experiment_results(results):\n",
    "    file_name_prefix =  'lr_hyper_params_experiments_results'\n",
    "    file_name = f'{file_name_prefix}_{time.monotonic_ns()}.pkl'\n",
    "    print(file_name)\n",
    "    with open(file_name, 'wb') as results_file:\n",
    "        pickle.dump(results, results_file)\n",
    "    return file_name\n",
    "        \n",
    "def classify(features_matrix, coeffs):\n",
    "    prob_predictions = predict_probability(features_matrix, coeff)\n",
    "    return prob_predictions > .5\n",
    "\n",
    "def load_results(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        return pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "hyper_params_experiments_results = load_results('lr_experiment_results_876800194845060.pkl')\n",
    "    \n",
    "print(len(hyper_params_experiments_results))\n",
    "\n",
    "hyper_params_experiments_results.append(\n",
    "    {'max_iterations': 101, 'penalty_type': 'l2', 'penalty_value': 100})\n",
    "hyper_params_experiments_results.append(\n",
    "    {'max_iterations': 501, 'penalty_type': 'l2', 'penalty_value': 100})\n",
    "hyper_params_experiments_results.append(\n",
    "    {'max_iterations': 1001, 'penalty_type': 'l2', 'penalty_value': 100})\n",
    "hyper_params_experiments_results.append(\n",
    "    {'max_iterations': 101, 'penalty_type': 'l1', 'penalty_value': 100})\n",
    "hyper_params_experiments_results.append(\n",
    "    {'max_iterations': 501, 'penalty_type': 'l1', 'penalty_value': 100})\n",
    "hyper_params_experiments_results.append(\n",
    "    {'max_iterations': 1001, 'penalty_type': 'l1', 'penalty_value': 100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16000, 5001) (5001,) (4000, 5001)\n",
      "---------------------------------\n",
      "{'max_iterations': 101, 'penalty_type': 'l2', 'penalty_value': 100}\n",
      "Minimum Probability:1.5642499285839832e-21, Maximum Probability:1.0, Current Accuracy: 0.9500625\n",
      "---------------------------------\n",
      "{'max_iterations': 501, 'penalty_type': 'l2', 'penalty_value': 100}\n",
      "Minimum Probability:9.356462064424788e-21, Maximum Probability:1.0, Current Accuracy: 0.9521875\n",
      "---------------------------------\n",
      "{'max_iterations': 1001, 'penalty_type': 'l2', 'penalty_value': 100}\n",
      "Minimum Probability:4.66073532162223e-20, Maximum Probability:1.0, Current Accuracy: 0.9525\n",
      "---------------------------------\n",
      "{'max_iterations': 101, 'penalty_type': 'l1', 'penalty_value': 100}\n",
      "Minimum Probability:1.8021828697023274e-22, Maximum Probability:1.0, Current Accuracy: 0.9506875\n",
      "---------------------------------\n",
      "{'max_iterations': 501, 'penalty_type': 'l1', 'penalty_value': 100}\n",
      "Minimum Probability:8.788829242675276e-24, Maximum Probability:1.0, Current Accuracy: 0.9556875\n",
      "---------------------------------\n",
      "{'max_iterations': 1001, 'penalty_type': 'l1', 'penalty_value': 100}\n",
      "Minimum Probability:5.898812559134921e-24, Maximum Probability:1.0, Current Accuracy: 0.957625\n",
      "lr_hyper_params_experiments_results_882488751903860.pkl\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "# Hyper Params\n",
    "\n",
    "step_size = 1e-5\n",
    "\n",
    "# Target Variables\n",
    "target_labels, target_label = y_train, 'Student loan'\n",
    "\n",
    "# Feature Matrix & Initial Coefficients\n",
    "X_train_features_matrix = count_vectorized_features_to_features_matrix(X_train_count_vectorizer)\n",
    "X_test_features_matrix = count_vectorized_features_to_features_matrix(X_test_count_vectorizer)\n",
    "\n",
    "initial_coefficients = np.zeros(X_train_features_matrix.shape[1])\n",
    "\n",
    "print(X_train_features_matrix.shape, initial_coefficients.shape, X_test_features_matrix.shape)\n",
    "\n",
    "for hyper_params in hyper_params_experiments_results:\n",
    "    if 'coeffs' in hyper_params:\n",
    "        continue\n",
    "    print('---------------------------------')\n",
    "    print(hyper_params)\n",
    "    start_time = datetime.datetime.now()\n",
    "    coeffs, likelihood_values = train_binary_lr_classifier(\n",
    "        X_train_features_matrix,\n",
    "        target_labels,\n",
    "        target_label,\n",
    "        initial_coefficients,\n",
    "        step_size = step_size,\n",
    "        max_iterations = hyper_params['max_iterations'],\n",
    "        penalty_type = hyper_params['penalty_type'],\n",
    "        penalty_value = hyper_params['penalty_value']\n",
    "    )\n",
    "    time_delta = datetime.datetime.now() - start_time\n",
    "    hyper_params['coeffs'] = coeffs\n",
    "    hyper_params['likelihood_values'] = likelihood_values\n",
    "    hyper_params['time_delta'] = time_delta\n",
    "    hyper_params['train_dataset_accuracy'] = accuracy_score(\n",
    "        y_train == 'Student loan',\n",
    "        classify(X_train_features_matrix, coeff))\n",
    "    hyper_params['test_dataset_accuracy'] = accuracy_score(\n",
    "        y_test == 'Student loan',\n",
    "        classify(X_test_features_matrix, coeff))\n",
    "\n",
    "LAST_RESULTS_FILE_NAME = save_experiment_results(hyper_params_experiments_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate different hyper parameters on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter: 101, penalty: l2, lambda: 0, train accuracy: 95.13125, test accuracy: 94.69999999999999\n",
      "max_iter: 501, penalty: l2, lambda: 0, train accuracy: 95.92500000000001, test accuracy: 95.575\n",
      "max_iter: 1001, penalty: l2, lambda: 0, train accuracy: 96.34375, test accuracy: 95.75\n",
      "max_iter: 101, penalty: l2, lambda: 10.0, train accuracy: 95.1375, test accuracy: 94.675\n",
      "max_iter: 501, penalty: l2, lambda: 1000.0, train accuracy: 90.84375, test accuracy: 90.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-24-97f8ba4e91aa>:4: RuntimeWarning: overflow encountered in exp\n",
      "  return 1.0 / (1 + np.exp(-scores))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter: 1001, penalty: l2, lambda: 100000.0, train accuracy: 80.0, test accuracy: 80.0\n",
      "max_iter: 101, penalty: l1, lambda: 10.0, train accuracy: 95.1375, test accuracy: 94.69999999999999\n",
      "max_iter: 501, penalty: l1, lambda: 1000.0, train accuracy: 93.33125, test accuracy: 92.77499999999999\n",
      "max_iter: 1001, penalty: l1, lambda: 100000.0, train accuracy: 80.0, test accuracy: 80.0\n",
      "max_iter: 101, penalty: l2, lambda: 100, train accuracy: 95.00625000000001, test accuracy: 94.5\n",
      "max_iter: 501, penalty: l2, lambda: 100, train accuracy: 95.21875, test accuracy: 94.825\n",
      "max_iter: 1001, penalty: l2, lambda: 100, train accuracy: 95.25, test accuracy: 94.675\n",
      "max_iter: 101, penalty: l1, lambda: 100, train accuracy: 95.06875000000001, test accuracy: 94.675\n",
      "max_iter: 501, penalty: l1, lambda: 100, train accuracy: 95.56875000000001, test accuracy: 95.19999999999999\n",
      "max_iter: 1001, penalty: l1, lambda: 100, train accuracy: 95.76249999999999, test accuracy: 95.25\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train_features_matrix = count_vectorized_features_to_features_matrix(X_train_count_vectorizer)\n",
    "X_test_features_matrix = count_vectorized_features_to_features_matrix(X_test_count_vectorizer)\n",
    "\n",
    "for hyper_params_result in hyper_params_experiments_results:\n",
    "    coeff = hyper_params_result['coeffs']\n",
    "    hyper_params_result['train_dataset_accuracy'] = accuracy_score(\n",
    "        y_train == 'Student loan',\n",
    "        classify(X_train_features_matrix, coeff))\n",
    "    hyper_params_result['test_dataset_accuracy'] = accuracy_score(\n",
    "        y_test == 'Student loan',\n",
    "        classify(X_test_features_matrix, coeff))\n",
    "    print(f\"max_iter: {hyper_params_result['max_iterations']},\",\n",
    "          f\"penalty: {hyper_params_result['penalty_type']},\",\n",
    "          f\"lambda: {hyper_params_result['penalty_value']},\",\n",
    "          f\"train accuracy: {hyper_params_result['train_dataset_accuracy'] * 100},\",\n",
    "          f\"test accuracy: {hyper_params_result['test_dataset_accuracy'] * 100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:937: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:937: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:937: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:937: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:937: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "cv_scores = cross_val_score(LogisticRegression(penalty='none', max_iter=101, random_state=RANDOM_STATE),\n",
    "                            X_train_count_vectorizer,\n",
    "                            y_train,\n",
    "                            cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8332499999999999\n",
      "[0.82875   0.8365625 0.825625  0.841875  0.8334375]\n"
     ]
    }
   ],
   "source": [
    "print(cv_scores.mean())\n",
    "print(cv_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (accuracy_score,\n",
    "                             confusion_matrix)\n",
    "\n",
    "import seaborn as sns;\n",
    "sns.set()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation on Test Dataset\n",
    "\n",
    "- Note: Retrain the model using full training [dataset](../datasets/consumer_complaints_training_dataset.csv) & test using the test [dataset](../datasets/consumer_complaints_test_dataset.csv)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Text Classification using Regularized Logistic Regression",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
